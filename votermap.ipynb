{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is based off of http://localhost:8820/notebooks/projects/demographics/Voting-2018-AW8.ipynb\n",
    "# and is intended to give access to the voter map from other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key is voter ID, DOB:str, reg_date:str, \n",
    "#    reg_info:{month_str: {status: , party: }}, addresses:{month_str:address}}\n",
    "#    vote_info:{vote_str: {party: , 'how': }}\n",
    "# vote_str is in the form GN_11_06_12 or PR_05_15_18 or PR_05_17_11\n",
    "# In the case of vote_info records added from fixed width files,\n",
    "#    'party' is set to be earliest known party and 'how' is None\n",
    "# In the case of those added from later files, 'how' is processed directly:\n",
    "#    'AP' indicates the voter cast their ballot at the polls\n",
    "#    'AB' indicates the voter cast an absentee ballot\n",
    "#    'P' indicates that the voter cast a provisional ballot\n",
    "# Added by voter_process_address_history:\n",
    "#   'addr_arr':[{'address': , 'date': , 'census_block': , 'latlon': },]\n",
    "\n",
    "# Initialize voter_map as empty if it doesn't already exist\n",
    "try:\n",
    "    voter_map\n",
    "except:\n",
    "    voter_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load voter_map \n",
    "#   voter_map_17_18_18.pickle has 'reg_date' as a string\n",
    "#   voter_map_17_18_18_b.pickle has 'reg_date' converted to datetime\n",
    "#   voter_map_09_17_18_18_c.pickle has data from 2009-07\n",
    "#   voter_map_09_17_18_18_d.pickle has census_block info (full for 15213, partial for all, need to do TODO addresses)\n",
    "#   voter_map_09_17_18_18_e.pickle has census_block info for all\n",
    "#   voter_map_09_17_18_18_f.pickle has census_block latlon info for all\n",
    "#   voter_map_09_17_18_18_g.pickle has fixups from processing of 2005-02 (delete pre-1900 DOB, deal with Date_Registered < DOB+18yrs)\n",
    "#   voter_map_05_09_13_17_18_18_18_h.pickle has voter history\n",
    "#   voter_map_05_09_13_17_18_18_18_i.pickle has census_block addresses resolutions for 2005-02 and 2013-02\n",
    "#   voter_map_05_09_13_17_18_18_18_j.pickle has initial fixup from 2005-02 and 2009-07 from running fixup_addr_dates\n",
    "#   voter_map_05_09_13_17_18_18_18_k.pickle has remaining fixups from 2013-02 through 2018-10 from running fixup_addr_dates\n",
    "#   voter_map_05_09_13_17_18_18_18_l.pickle has more fixups from running voter_crosscheck_address_history_array and regenerating census block dots\n",
    "\n",
    "voter_map_file_path_t = 'voters/voter_map_{}.pickle'\n",
    "default_vm_suffix = '05_09_13_17_18_18_18_l'\n",
    "\n",
    "def save_voter_map(suffix):\n",
    "    global voter_map\n",
    "    \n",
    "    if not suffix:\n",
    "        print \"ERROR: need to specify suffix to save voter_map.  Default load suffix is %s\"%(default_vm_suffix)\n",
    "    voter_map_file_path = voter_map_file_path_t.format(suffix)\n",
    "    \n",
    "    print 'Saving voter_map to %s'%(voter_map_file_path)\n",
    "    \n",
    "    # Save out voter_map\n",
    "    with open(voter_map_file_path, 'wb') as handle:\n",
    "        pickle.dump(voter_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_voter_map(suffix):\n",
    "    global voter_map\n",
    "\n",
    "    if not suffix:\n",
    "        suffix = default_vm_suffix\n",
    "    voter_map_file_path = voter_map_file_path_t.format(suffix)\n",
    "    \n",
    "    print 'Loading voter_map from %s'%(voter_map_file_path)\n",
    "\n",
    "    # Load in voter_map\n",
    "    with open(voter_map_file_path, 'rb') as handle:\n",
    "        voter_map = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key is vote_str, value is {'date': datetime, 'month_strs': set(month_str),'date_type': }\n",
    "# 'date_type' is 'exact' if we actually knew the date, or 'approx' if we're just guessing\n",
    "# strings generated from fixed width files will be created as 'approx' dates; those\n",
    "# created by newer files will be 'exact'.  \n",
    "\n",
    "# Initialize vote_map as empty if it doesn't already exist\n",
    "try:\n",
    "    vote_map\n",
    "except:\n",
    "    vote_map= {}\n",
    "    \n",
    "# vote_arr is an ordered list of tuples in time order [(vs1, date1), (vs2, date2)...]\n",
    "# The invariant is that when an item is added to vote_map, vote_arr must be regenerated\n",
    "# appropriately\n",
    "try:\n",
    "    vote_arr\n",
    "except:\n",
    "    vote_arr = []\n",
    "\n",
    "# This is an array mapping from the index of Vote_History strings into \n",
    "# vote_str strings.  Earlier than the first exact date strings these are just \n",
    "# PR_YYYY and GN_YYYY.  After the first exact date strings, these are PR_MM_DD_YY\n",
    "try:\n",
    "    vote_history_index_to_vote_str\n",
    "except:\n",
    "    vote_history_index_to_vote_str=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/save for vote_info elements\n",
    "#   vote_info_05_09_13_17_18_18_18_a.pickle is the initial save after loading vote info from 2005, 2013, and 2018\n",
    "\n",
    "vote_info_file_path_t = 'voters/vote_info_{}_{}.pickle'\n",
    "default_vi_suffix = '05_09_13_17_18_18_18_a'\n",
    "\n",
    "def save_vote_info(suffix):\n",
    "    global vote_map\n",
    "    global vote_arr\n",
    "    global vote_history_index_to_vote_str\n",
    "    if not suffix:\n",
    "        print \"ERROR: need to specify suffix to save vote_info.  Default load suffix is %s\"%(default_vi_suffix)\n",
    "\n",
    "    vote_info_file_path={}\n",
    "    for elt in ['map','arr','index']:\n",
    "        vote_info_file_path[elt] = vote_info_file_path_t.format(elt,suffix)\n",
    "        print 'Saving vote_%s to %s'%(elt, vote_info_file_path[elt])\n",
    "    \n",
    "    # Save out vote_info elements\n",
    "    with open(vote_info_file_path['map'], 'wb') as handle:\n",
    "        pickle.dump(vote_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(vote_info_file_path['arr'], 'wb') as handle:\n",
    "        pickle.dump(vote_arr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(vote_info_file_path['index'], 'wb') as handle:\n",
    "        pickle.dump(vote_history_index_to_vote_str, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_vote_info(suffix):\n",
    "    global vote_map\n",
    "    global vote_arr\n",
    "    global vote_history_index_to_vote_str\n",
    "\n",
    "    if not suffix:\n",
    "        suffix = default_vi_suffix\n",
    "    \n",
    "    vote_info_file_path={}\n",
    "    for elt in ['map','arr','index']:\n",
    "        vote_info_file_path[elt] = vote_info_file_path_t.format(elt,suffix)\n",
    "        print 'Loading vote_%s from %s'%(elt, vote_info_file_path[elt])\n",
    "\n",
    "    # Load in vote_info elements\n",
    "    with open(vote_info_file_path['map'], 'rb') as handle:\n",
    "        vote_map = pickle.load(handle)\n",
    "    with open(vote_info_file_path['arr'], 'rb') as handle:\n",
    "        vote_arr = pickle.load(handle)\n",
    "    with open(vote_info_file_path['index'], 'rb') as handle:\n",
    "        vote_history_index_to_vote_str = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time vote_map is changed in a way that affects dates this should be called\n",
    "# so we always have a sorted list of votes\n",
    "def regenerate_vote_arr():\n",
    "    global vote_arr\n",
    "    global vote_map\n",
    "    vote_arr = sorted(vote_map.items(),key=lambda x:x[1]['date'])\n",
    "\n",
    "# Vote strings are in the form TT_MM_DD_YY, parse the date\n",
    "def vote_str_to_date(vote_str):\n",
    "    str_date = datetime.datetime.strptime(vote_str[3:], '%m_%d_%y')\n",
    "    return(str_date)\n",
    "\n",
    "# Given a list of column names return a list of vote_str values included in the dataframe\n",
    "# and populate vote_map with the date if we don't already have it\n",
    "def columns_to_vote_strs(month_str, column_list):\n",
    "    global vote_arr\n",
    "    global vote_map\n",
    "\n",
    "    # Process any new style column names\n",
    "    vote_str_list = list(filter(lambda x: ('GN_' in x or 'PR_' in x or 'SP_' in x) and (not '_VM' in x), \n",
    "                                column_list))\n",
    "    \n",
    "    for vote_str in vote_str_list:\n",
    "        if not vote_str in vote_map:\n",
    "            vote_map[vote_str] = {'date': vote_str_to_date(vote_str), \n",
    "                                  'month_strs': set([month_str]), \n",
    "                                  'date_type':'exact'\n",
    "                                 }\n",
    "        else:\n",
    "            vote_map[vote_str]['month_strs'].add(month_str)\n",
    "            \n",
    "    regenerate_vote_arr()\n",
    "    return(vote_str_list)\n",
    "\n",
    "# Old style Vote_History from fixed width files start with the primary of 1983 but only have\n",
    "# 2 bits of info about each election: '0' = not registered, '1' = voted, '2' = didn't vote\n",
    "# we don't know exact dates or party affiliation.\n",
    "\n",
    "# Add entries into vote_map for the longest of these, which is currently 2009.\n",
    "# Before calling this, dadd '2013-02', or whatever the oldest of the new style \n",
    "# files are, so vote_map contains exact entries for the earliest dates it can\n",
    "\n",
    "# See the file VoterThankYou-12Dec2007 in https://drive.google.com/drive/folders/1xVsl029scwhnVnXa-v6XpFufjOavNrhe\n",
    "# for definitions on the format of the Vote_History string\n",
    "def add_vote_history_map_entries():\n",
    "    global voter_map\n",
    "    \n",
    "    first_new_style_year = 2004\n",
    "    last_new_style_year = 2010\n",
    "    history_month_str = '2005-02'\n",
    "    new_style_names = list(filter(lambda x: ('GN_' in x or 'PR_' in x),vote_map.keys()))\n",
    "    \n",
    "    idx = 0\n",
    "    for year in range(1983, last_new_style_year):\n",
    "        pr_name = \"PR_%4d\"%(year)\n",
    "        gn_name = \"GN_%4d\"%(year)\n",
    "        # Estimate priaries as 5/16/YYYY and general elections as 11/6/YYYY if we don't know \n",
    "        # any better\n",
    "        pr_date = dateparser.parse(\"5/16/%d\"%(year))\n",
    "        gn_date = dateparser.parse(\"11/6/%d\"%(year))\n",
    "        pr_type = 'approx'\n",
    "        gn_type = 'approx'\n",
    "        if(year>=first_new_style_year):\n",
    "            # Try to retrieve the exact dates from vote_map\n",
    "            yy = (\"%d\"%(year))[2:4]\n",
    "            pr_names = list(filter(lambda x: bool(re.search('PR_\\d\\d_\\d\\d_%s'%(yy), x)), \n",
    "                                 new_style_names))\n",
    "            gn_names = list(filter(lambda x: bool(re.search('GN_\\d\\d_\\d\\d_%s'%(yy), x)), \n",
    "                                 new_style_names))\n",
    "            #print \"%d: Search for %s: pr=%r, gn=%r\" % (idx, yy, pr_names, gn_names)\n",
    "            if(len(pr_names)==1):\n",
    "                pr_name = pr_names[0]\n",
    "                pr_date = vote_map[pr_name]['date']\n",
    "                pr_type = vote_map[pr_name]['date_type']\n",
    "            if(len(gn_names)==1):\n",
    "                gn_name = gn_names[0]\n",
    "                gn_date = vote_map[gn_name]['date']\n",
    "                gn_type = vote_map[gn_name]['date_type']\n",
    "        # Do PR then GN for this year and increment index \n",
    "        vote_history_index_to_vote_str.append(pr_name)\n",
    "        vote_history_index_to_vote_str.append(gn_name)\n",
    "        idx = idx+2\n",
    "        \n",
    "        # Add to vote_map\n",
    "        if not pr_name in vote_map:\n",
    "            vote_map[pr_name] = {'date': pr_date, \n",
    "                                  'month_strs': set([history_month_str]), \n",
    "                                  'date_type':pr_type\n",
    "                                 }\n",
    "        else:\n",
    "            vote_map[pr_name]['month_strs'].add(history_month_str)\n",
    "            \n",
    "        if not gn_name in vote_map:\n",
    "            vote_map[gn_name] = {'date': gn_date, \n",
    "                                  'month_strs': set([history_month_str]), \n",
    "                                  'date_type':gn_type\n",
    "                                 }\n",
    "        else:\n",
    "            vote_map[gn_name]['month_strs'].add(history_month_str)\n",
    "            \n",
    "    # Udpdate vote_arr to make sure new entries are in there and in order\n",
    "    regenerate_vote_arr()\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# Individual voter vote_info support\n",
    "# Given the existing vote_info_map for a voter, add an entry for \n",
    "# a given vote_str, party, and how.  \n",
    "def add_vote_record(vote_info_map, vote_str, party, how):\n",
    "    if vote_str in vote_info_map:\n",
    "        # There's already an entry.  Is this new info better?\n",
    "        if(how and not vote_info_map[vote_str]['how']):\n",
    "            # This new info is better, use it\n",
    "            vote_info_map[vote_str]['how']=how\n",
    "            vote_info_map[vote_str]['party']=party\n",
    "        else:\n",
    "            # This is a duplicate, ignore it\n",
    "            pass\n",
    "    else:\n",
    "        # There's not an entry yet, create one\n",
    "        vote_info_map[vote_str]={'party': party, 'how':how}\n",
    "        \n",
    "\n",
    "# Find all the '1's in the history str, translate those into \n",
    "def process_vote_history(vote_info_map, history_str, party):\n",
    "    idx=0\n",
    "    while(idx != -1 and idx < len(history_str)):\n",
    "        # Find the index of the next '1'\n",
    "        new_idx = history_str.find('1', idx)\n",
    "        #print \"Found %d (%d)\"% (new_idx,idx)\n",
    "        if(new_idx!=-1):\n",
    "            # Found a vote that this voter participated in\n",
    "            vote_str = vote_history_index_to_vote_str[new_idx] if new_idx < len(vote_history_index_to_vote_str) else None\n",
    "            if(vote_str):\n",
    "                add_vote_record(vote_info_map, vote_str, party, None)\n",
    "            else:\n",
    "                print \"WARNING: No entry in vote_history_index_to_vote_str for index %d\"% (new_idx)\n",
    "                break\n",
    "            idx=new_idx+1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return(vote_info_map)\n",
    "                \n",
    "def process_vote_columns(vote_info_map, df, i):\n",
    "    vote_strs = columns_to_vote_strs(month_str, list(df))\n",
    "    for vote_str in vote_strs:\n",
    "        if not pd.isna(df[vote_str].iloc[i]):\n",
    "            # They voted in this one, find out how\n",
    "            party = df[vote_str].iloc[i]\n",
    "            how = df[\"%s_VM\"%(vote_str)].iloc[i]\n",
    "            add_vote_record(vote_info_map, vote_str, party, how)\n",
    "\n",
    "    return(vote_info_map)\n",
    "\n",
    "def get_next_vote_str_rec_after_date(vote_info_map, cmp_date):\n",
    "    if(not cmp_date):\n",
    "        return None\n",
    "    \n",
    "    # Find and return the next item after this one in vote_arr or None if we're past the end \n",
    "    return (next((item for item in vote_arr if item[0] in vote_info_map and item[1][\"date\"] > cmp_date),None))\n",
    "\n",
    "def get_vote_str_rec_on_or_after_date(vote_info_map, cmp_date):\n",
    "    # Find and return the next item after this one in vote_arr or None if we're past the end \n",
    "    return (next((item for item in vote_arr if item[0] in vote_info_map and item[1][\"date\"] >= cmp_date),None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a voter ID, and address, find and return a tuple of (i,addr_rec) if there\n",
    "# is an entry in addr_arr matching the address.  If no match, return None\n",
    "# TODO: What if there are multiple entries with the same address?\n",
    "def find_matching_addr_rec(vid, addr):\n",
    "    global voter_map\n",
    "    \n",
    "    # Make sure vid is in voter_map\n",
    "    if(not vid in voter_map):\n",
    "        return None\n",
    "    vrec = voter_map[vid]\n",
    "    if(not 'addr_arr' in vrec):\n",
    "        return None\n",
    "    # Find the entry in addr_arr matching this address\n",
    "    for i in range(0,len(voter_map[vid]['addr_arr'])):\n",
    "        if(addr == voter_map[vid]['addr_arr'][i]['address']):\n",
    "            return(i,voter_map[vid]['addr_arr'][i])\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of what month_strs are in the current voter_map\n",
    "try:\n",
    "    active_month_str_set\n",
    "    active_month_str_arr\n",
    "except:\n",
    "    active_month_str_set=set(['2005-02', '2009-07', '2013-02', '2017-11', '2018-03', '2018-08', '2018-10'])\n",
    "    active_month_str_arr=sorted(list(active_month_str_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/load voter_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use  random points in census blocks for voter IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    block_id_use_map\n",
    "except:\n",
    "    print \"WARNING: block_id_use_map not defined.  exec_ipynb('block_points.ipynb')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_get_voter_coords(census_block, vid):\n",
    "    global block_id_use_map\n",
    "    \n",
    "    if(not census_block in block_id_use_map):\n",
    "        # Need to create an entry, set 'next' to 0, initialize points\n",
    "        # First convert from GEOID10 to the index into the block_idx\n",
    "        block_idx = geoid2idx[census_block]\n",
    "        point_arr = block_points(block_idx)\n",
    "        block_id_use_map[census_block]={'next':0, 'numpoints':len(point_arr)}\n",
    "        block_points_map[census_block]=point_arr\n",
    "    elif(not census_block in block_points_map):\n",
    "        # We have an entry in block_id_use_map for this census_block, \n",
    "        # but not in block_points_map.  This can happen if we restore\n",
    "        # block_id_use_map from a saved file.  Use block_points to fill in \n",
    "        # block_points_map\n",
    "        block_idx = geoid2idx[census_block]\n",
    "        point_arr = block_points(block_idx)\n",
    "        block_points_map[census_block]=point_arr\n",
    "        \n",
    "    # We know census_block is in block_id_use_map (which we may have just added)\n",
    "    # Check if this voter ID is already registered\n",
    "    if(vid in block_id_use_map[census_block]):\n",
    "        # Already assigned, just use the same index as before\n",
    "        point_idx=block_id_use_map[census_block][vid]\n",
    "    else:\n",
    "        # Not yet assigned, take the next available \n",
    "        # and increment 'next'\n",
    "        point_idx = block_id_use_map[census_block]['next']\n",
    "        if(point_idx>block_id_use_map[census_block]['numpoints']-1):\n",
    "            # Overflow\n",
    "            if(not census_block in block_id_overflow_set):\n",
    "                block_id_overflow_set.add(census_block)\n",
    "                print \"WARNING: overflow in census block %s\" % (census_block)\n",
    "            # For now, just start reassigning numbers back at 0\n",
    "            point_idx=0\n",
    "            block_id_use_map[census_block]['next']=0\n",
    "        block_id_use_map[census_block]['next'] = point_idx + 1\n",
    "        block_id_use_map[census_block][vid] = point_idx\n",
    "        \n",
    "    # Retrieve the webmercator point from the points array.\n",
    "    # Convert it to lat lon and create a Point to return.\n",
    "    # Note that WebMercatorToLonLat(x,y) returns [lon, lat]\n",
    "    # the args to create a Point are also (lon, lat)\n",
    "    point_xy = block_points_map[census_block][point_idx]\n",
    "    ll_arr = WebMercatorToLonLat(point_xy['x'],point_xy['y'])\n",
    "    return Point(ll_arr[0], ll_arr[1])\n",
    "\n",
    "def voter_get_coords_for_addr_history(vid, force_update):\n",
    "    global voter_map\n",
    "    \n",
    "    if(not vid in voter_map):\n",
    "        print \"WARNING: %s not in voter_map\" % (vid)\n",
    "        return\n",
    "    vrec = voter_map[vid]\n",
    "    if(not 'addr_arr' in vrec):\n",
    "        print \"WARNING: %s missing addr_arr in voter_map, re-run voter_process_address_history_array\" % (vid)\n",
    "        return\n",
    "\n",
    "    addr_arr = vrec['addr_arr']\n",
    "    for j in range(0,len(addr_arr)):\n",
    "        addr_rec = vrec['addr_arr'][j]\n",
    "        if('latlon' in addr_rec and not force_update):\n",
    "            continue\n",
    "        if(not 'census_block' in addr_rec):\n",
    "            print \"WARNING %s: '%s' lacks 'census_block', skipping\" % (vid, this_addr)\n",
    "            continue\n",
    "        # census_block might be None, in which case don't get coords\n",
    "        if(addr_rec['census_block']==None):\n",
    "            continue\n",
    "        try:\n",
    "            coords = block_get_voter_coords(addr_rec['census_block'], vid)\n",
    "            #print \"Assigning %r to %s[%d]='%s'\"%(coords, vid,j,addr_rec['census_block'])\n",
    "            #voter_map[vid]['addr_arr'][j]['latlon'] = coords\n",
    "            addr_rec['latlon'] = coords\n",
    "        except Exception as e:\n",
    "            print \"ERROR: Exception getting coords for %s[%d]='%s': %s\"%(vid,j,addr_rec['census_block'],e)\n",
    "\n",
    "def voter_get_coords_for_addr_history_array(vid_arr, force_update):\n",
    "    start=arrow.now()\n",
    "    chunk_start_time=start\n",
    "    chunk_size=10000\n",
    "\n",
    "    for i in range(0,len(vid_arr)):\n",
    "        vid = vid_arr[i]\n",
    "        voter_get_coords_for_addr_history(vid, force_update)\n",
    "        \n",
    "        # Handle periodic debug message\n",
    "        if((i%chunk_size)==0 and i>0):\n",
    "            print \"%d-%d: processing %r, %s time elapsed\" %(i-(chunk_size-1), i, vid,arrow.now()-chunk_start_time)\n",
    "            addcnt=0\n",
    "            chunk_start_time=arrow.now()\n",
    "\n",
    "    end=arrow.now()\n",
    "    print \"Processing took %s for %d addresses\" % (str(end-start), len(vid_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
