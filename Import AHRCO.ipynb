{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version uses Allegheny_County_All_Properties.csv, \n",
    "# the Allegheny county subset of the full preservation database\n",
    "# generated by all-properties-preservation-database.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate from Randy cheatsheet at https://docs.google.com/document/d/1utZuLHcKQEZNXTQLOysTNCxTHrqxczAUymmtplpn27Q/edit#\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook-container { margin-left:-14px; width:calc(100% + 27px) !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wide display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>#notebook-container { margin-left:-14px; width:calc(100% + 27px) !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, os, math, numbers, pandas, re, scipy, scipy.sparse, shutil, arrow\n",
    "import subprocess, sys, threading, time, urllib2\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "exec_ipynb('timelapse-utilities.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.options.display.max_colwidth = 300\n",
    "pandas.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_year=2017\n",
    "latest_year=2018\n",
    "\n",
    "def process_cosima_csv(path):\n",
    "    parsed_pd_data=[]\n",
    "    pd_data = pandas.read_csv(path)\n",
    "    \n",
    "    for i in range(0,len(pd_data.index)):\n",
    "        try:\n",
    "            rec = {'row':i}\n",
    "            rec['lat']= pd_data['Latitude'][i]\n",
    "            rec['lon']= pd_data['Longitude'][i]\n",
    "            # We don't know the sizes, so we just pull something from thin air\n",
    "            rec['total_units'] = 20\n",
    "            reac_years = []\n",
    "            reac_vals = []\n",
    "            for j in range(3,0,-1):\n",
    "                reac_str = \"ReacScore%d\"%(j)\n",
    "                # Check if this reac score is missing\n",
    "                if(pandas.isnull(pd_data['%s'%(reac_str)][i]) or pandas.isnull(pd_data['%sDate'%(reac_str)][i])):\n",
    "                    continue\n",
    "                # Something non-null is there, hope it's valid!\n",
    "                reac_years.append(pandas.to_datetime(pd_data['%sDate'%(reac_str)][i]).date().year)\n",
    "                reac_vals.append(pd_data['%s'%(reac_str)][i])\n",
    "            rec['reac_years'] = reac_years\n",
    "            rec['reac_vals'] = reac_vals\n",
    "            # There's no set of programs specified, just set year range to have two columns\n",
    "            rec['start_year']=earliest_year\n",
    "            rec['end_year']=latest_year\n",
    "            parsed_pd_data.append(rec)\n",
    "        except Exception as e:\n",
    "            print \"%s: Skipping row %d, zip %s, due to error %s\" % (program_arr,i,zip,e)\n",
    "    return parsed_pd_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parsed_ahrco_data = process_cosima_csv(\"https://docs-proxy.cmucreatelab.org/spreadsheets/d/1SasXUMnzGxxnaktgB1GnsA0jjEGOagEQszqiB2nxIZM/export?format=csv&gid=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_hud_data = process_cosima_csv(\"https://docs-proxy.cmucreatelab.org/spreadsheets/d/1SasXUMnzGxxnaktgB1GnsA0jjEGOagEQszqiB2nxIZM/export?format=csv&gid=1970308521\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_hud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pd_csv(parsed_pd_data, start_year, end_year, out_path):\n",
    "    date_range = range(start_year, end_year+1)\n",
    "    out = open(out_path, 'w')\n",
    "    # Write out header row.  First column doesn't have a column heading, next two are lat, lon, then each year\n",
    "    out.write(\",lat,lon,%s\\n\" % (\",\".join(map(str,date_range))))\n",
    "    \n",
    "    i=0\n",
    "    for rec in parsed_pd_data:\n",
    "        start_year = rec['start_year']\n",
    "        end_year = rec['end_year']\n",
    "        out_data=[i, rec['lat'], rec['lon']]\n",
    "        i=i+1\n",
    "        \n",
    "        for year in date_range:\n",
    "            out_val = 0\n",
    "            # If csv type is:\n",
    "            #  'all' or 'total', use total_units\n",
    "            #  'current', use size for year >= start_year and year< end_year (green)\n",
    "            #  'expiring', use size for year == end_year (yellow)\n",
    "            #  'expired', use size for year > end_year (red)\n",
    "            out_val = rec['total_units']\n",
    "            out_data.append(out_val)\n",
    "        out.write('%s\\n' % (\",\".join(map(str,out_data))))\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pd_csv(parsed_ahrco_data, 2017, 2018, \"preservationdatabase/pgh_ahrco_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pd_csv(parsed_hud_data, 2017, 2018, \"preservationdatabase/pgh_hud_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses colormap https://tiles.earthtime.org/colormaps/grey-red-yellow-green.png\n",
    "a_val=1\n",
    "b_val=0.666\n",
    "c_val=0.333\n",
    "unknown_val=0\n",
    "def write_reac_code_pd_csv(parsed_pd_data, start_year, end_year, out_path):\n",
    "    date_range = range(start_year, end_year+1)\n",
    "    out = open(out_path, 'w')\n",
    "    # Write out header row.  First column doesn't have a column heading, next two are lat, lon, then each year\n",
    "    out.write(\",lat,lon,%s\\n\" % (\",\".join(map(str,date_range))))\n",
    "    \n",
    "    i=0\n",
    "    for rec in parsed_pd_data:\n",
    "        # If we have no reac scores, skip this one\n",
    "        if(len(rec['reac_years'])==0):\n",
    "            start_year = 2017\n",
    "            end_year = 2018\n",
    "        else:            \n",
    "            # Set start_year to be earliest reac_year and end_year to be latest reac_year\n",
    "            start_year = rec['reac_years'][0]\n",
    "            end_year = rec['reac_years'][len(rec['reac_years'])-1]\n",
    "            \n",
    "        #Output two rows, both with the same label.  First row is bubble size.  Second row is 0 - 1 for status\n",
    "        row_label = i\n",
    "        i=i+1\n",
    "        \n",
    "        units=0\n",
    "        if(not 'assisted_units' in rec.keys()):\n",
    "            units = rec['total_units']\n",
    "        else:\n",
    "            units = rec['assisted_units']\n",
    "        bubble_size = units\n",
    "        \n",
    "        # Bubble size row -- size is constant\n",
    "        size_row=[row_label, rec['lat'], rec['lon']]\n",
    "\n",
    "        for year in date_range:\n",
    "            if(len(rec['reac_years'])>0):\n",
    "                size_row.append(bubble_size)\n",
    "            else:\n",
    "                size_row.append(5)\n",
    "            \n",
    "        # Bubble color row -- value depends on status\n",
    "        color_row=[row_label, rec['lat'], rec['lon']]\n",
    "\n",
    "        # Earliest year will be \n",
    "        reac_i = 0\n",
    "        # If we don't know a reac value, just set it arbitrarily to be 66.  If we do know a reac value this will be overridden by the right stuff later\n",
    "        last_reac_val = \"66b\"\n",
    "        last_reac_year = 2018\n",
    "        if(len(rec['reac_years'])>0):\n",
    "            last_reac_val = rec['reac_vals'][0]\n",
    "            last_reac_year = rec['reac_years'][0]\n",
    "            \n",
    "        for year in date_range:\n",
    "            color_val=0\n",
    "            # Check if we need to increment reac_i to a later test date\n",
    "            while(year>last_reac_year and reac_i<(len(rec['reac_years'])-1)):\n",
    "                last_reac_val = rec['reac_vals'][reac_i]\n",
    "                reac_i=reac_i+1\n",
    "                last_reac_year = rec['reac_years'][reac_i]\n",
    "\n",
    "            # If we've caught up to the last reac_year, set last_reac_val to the end one\n",
    "            if(reac_i==(len(rec['reac_years'])-1) and year>=end_year):\n",
    "                last_reac_val = rec['reac_vals'][reac_i]\n",
    "                \n",
    "            # At this point last_reac_val is valid for this year so long as year>=start_year.\n",
    "            # If year < start_year, set color to unknown_val\n",
    "            #if (year < start_year):\n",
    "            #    color_val = unknown_val\n",
    "            #else:\n",
    "            \n",
    "            # Randy doesn't want it to start as grey\n",
    "            if('a' in last_reac_val):\n",
    "                color_val = a_val\n",
    "            elif('b' in last_reac_val):\n",
    "                color_val = b_val\n",
    "            elif('c' in last_reac_val):\n",
    "                color_val = c_val\n",
    "            else:\n",
    "                color_val = unknown_val\n",
    "            color_row.append(color_val)\n",
    "            \n",
    "        # Write both rows for this property out here\n",
    "        out.write('%s\\n' % (\",\".join(map(str,size_row))))\n",
    "        out.write('%s\\n' % (\",\".join(map(str,color_row))))\n",
    "        \n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_reac_code_pd_csv(parsed_ahrco_data, 2003, 2018, \"preservationdatabase/pgh_reac_code_ahrco_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_reac_code_pd_csv(parsed_hud_data, 2003, 2018, \"preservationdatabase/pgh_reac_code_hud_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses colormap https://tiles.earthtime.org/colormaps/grey-red-yellow-green.png\n",
    "unknown_val=0\n",
    "def write_reac_val_pd_csv(parsed_pd_data, start_year, end_year, out_path):\n",
    "    date_range = range(start_year, end_year+1)\n",
    "    out = open(out_path, 'w')\n",
    "    \n",
    "    # Setup regular expression for parsing reac score\n",
    "    reac_re = re.compile('(\\d+)([abc])(\\*?)')\n",
    "\n",
    "    # Write out header row.  First column doesn't have a column heading, next two are lat, lon, then each year\n",
    "    out.write(\",lat,lon,%s\\n\" % (\",\".join(map(str,date_range))))\n",
    "    \n",
    "    i=0\n",
    "    for rec in parsed_pd_data:\n",
    "        if(len(rec['reac_years'])==0):\n",
    "            start_year = 2017\n",
    "            end_year = 2018\n",
    "        else:            \n",
    "            # Set start_year to be earliest reac_year and end_year to be latest reac_year\n",
    "            start_year = rec['reac_years'][0]\n",
    "            end_year = rec['reac_years'][len(rec['reac_years'])-1]\n",
    "\n",
    "        #Output two rows, both with the same label.  First row is bubble size.  Second row is 0 - 1 for status\n",
    "        row_label = i\n",
    "        i=i+1\n",
    "        \n",
    "        units=0\n",
    "        if(not 'assisted_units' in rec.keys()):\n",
    "            units = rec['total_units']\n",
    "        else:\n",
    "            units = rec['assisted_units']\n",
    "        bubble_size = units\n",
    "        \n",
    "        # Bubble size row -- size is constant\n",
    "        size_row=[row_label, rec['lat'], rec['lon']]\n",
    "\n",
    "        for year in date_range:\n",
    "            size_row.append(bubble_size)\n",
    "            \n",
    "        # Bubble color row -- value depends on status\n",
    "        color_row=[row_label, rec['lat'], rec['lon']]\n",
    "\n",
    "        # Earliest year will be \n",
    "        reac_i = 0\n",
    "        # If we don't know a reac value, just set it arbitrarily to be 66.  If we do know a reac value this will be overridden by the right stuff later\n",
    "        last_reac_val = \"66b\"\n",
    "        last_reac_year = 2018\n",
    "        if(len(rec['reac_years'])>0):\n",
    "            last_reac_val = rec['reac_vals'][0]\n",
    "            last_reac_year = rec['reac_years'][0]\n",
    "\n",
    "        for year in date_range:\n",
    "            color_val=0\n",
    "            # Check if we need to increment reac_i to a later test date\n",
    "            while(year>last_reac_year and reac_i<(len(rec['reac_years'])-1)):\n",
    "                last_reac_val = rec['reac_vals'][reac_i]\n",
    "                reac_i=reac_i+1\n",
    "                last_reac_year = rec['reac_years'][reac_i]\n",
    "\n",
    "            # If we've caught up to the last reac_year, set last_reac_val to the end one\n",
    "            if(reac_i==(len(rec['reac_years'])-1) and year>=end_year):\n",
    "                last_reac_val = rec['reac_vals'][reac_i]\n",
    "                \n",
    "            # At this point last_reac_val is valid for this year so long as year>=start_year.\n",
    "            # If year < start_year, set color to unknown_val\n",
    "            #if (year < start_year):\n",
    "            #    color_val = unknown_val\n",
    "            #else:\n",
    "            # Randy doesn't want it to start as grey\n",
    "            if(True):\n",
    "                # Strip the number from the front of the reac string\n",
    "                m = reac_re.match(last_reac_val)\n",
    "                # The number will be in the first group\n",
    "                color_val = int(m.group(1))\n",
    "            color_row.append(color_val)\n",
    "            \n",
    "        # Write both rows for this property out here\n",
    "        out.write('%s\\n' % (\",\".join(map(str,size_row))))\n",
    "        out.write('%s\\n' % (\",\".join(map(str,color_row))))\n",
    "        \n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_reac_val_pd_csv(parsed_ahrco_data, 2003, 2018, \"preservationdatabase/pgh_reac_val_ahrco_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_reac_val_pd_csv(parsed_hud_data, 2003, 2018, \"preservationdatabase/pgh_reac_val_hud_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was the old path that only included non-expired properties\n",
    "#pgh_path = \"preservationdatabase/Active and Inconclusive Properties Pgh.xlsx\"\n",
    "# This is the new path that includes all properties\n",
    "pgh_path = \"preservationdatabase/Allegheny_County_All_Properties.csv\"\n",
    "# Removed \"S8_2\" because S8_2_AssistedUnits1, S8_2_StartTime1, S8_2_EndTime1 don't follow the pattern\n",
    "#for program in [\"S8_1\",\"S202_1\",\"S202_2\",\"S236_1\",\"S236_2\",\"FHA_1\",\"FHA_2\",\"LIHTC_1\",\"LIHTC_2\"]:\n",
    "for program_info in [{'name':'S8_m','programs':[\"S8_1\",\"S8_2\"]},\n",
    "                     {'name':'S202_m','programs':[\"S202_1\",\"S202_2\"]},\n",
    "                     {'name':'S236_m','programs':[\"S236_1\",\"S236_2\"]},\n",
    "                     {'name':'FHA_m','programs':[\"FHA_1\",\"FHA_2\"]},\n",
    "                     {'name':'LIHTC_m','programs':[\"LIHTC_1\",\"LIHTC_2\"]}]:\n",
    "    program = program_info['name']\n",
    "    program_arr = program_info['programs']\n",
    "    parsed_pgh_data = process_preservationdatabase_csv(pgh_path,program_arr)\n",
    "\n",
    "    #write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_current_%s_2018.csv\"%(program),'current')\n",
    "    #write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_expiring_%s_2018.csv\"%(program),'expiring')\n",
    "    #write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_expired_%s_2018.csv\"%(program),'expired')\n",
    "    #write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_total_%s_2018.csv\"%(program),'total')\n",
    "    #write_combo_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_combo_%s_a_2018.csv\"%(program))\n",
    "    write_reac_code_pd_csv(parsed_pgh_data, 2003,2018,\"preservationdatabase/pgh_reac_code_%s_a_2018.csv\"%(program))\n",
    "    write_reac_val_pd_csv(parsed_pgh_data, 2003,2018,\"preservationdatabase/pgh_reac_val_%s_a_2018.csv\"%(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_preservationdatabase_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5bd3ea31742a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_pgh_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_preservationdatabase_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgh_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_all_2018.csv\",'all')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_elderly_2018.csv\",'elderly')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_family_2018.csv\",'family')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_disabled_2018.csv\",'disabled')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_preservationdatabase_csv' is not defined"
     ]
    }
   ],
   "source": [
    "parsed_pgh_data = process_preservationdatabase_csv(pgh_path,[])\n",
    "#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_all_2018.csv\",'all')\n",
    "#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_elderly_2018.csv\",'elderly')\n",
    "#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_family_2018.csv\",'family')\n",
    "#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_disabled_2018.csv\",'disabled')\n",
    "#write_pd_csv(parsed_pgh_data, 2017,2051,\"preservationdatabase/pgh_mixed_2018.csv\",'mixed')\n",
    "write_reac_code_pd_csv(parsed_pgh_data, 2003,2018,\"preservationdatabase/pgh_reac_code_all_a_2018.csv\")\n",
    "write_reac_val_pd_csv(parsed_pgh_data, 2003,2018,\"preservationdatabase/pgh_reac_val_all_a_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_pgh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tiles.earthtime.org/preservationdatabase/pgh_current_S8_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expiring_S8_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expired_S8_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_total_S8_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_current_S202_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expiring_S202_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expired_S202_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_total_S202_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_current_S236_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expiring_S236_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expired_S236_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_total_S236_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_current_FHA_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expiring_FHA_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expired_FHA_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_total_FHA_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_current_LIHTC_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expiring_LIHTC_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_expired_LIHTC_m_2018.csv\n",
      "https://tiles.earthtime.org/preservationdatabase/pgh_total_LIHTC_m_2018.csv\n"
     ]
    }
   ],
   "source": [
    "for program_info in [{'name':'S8_m','programs':[\"S8_1\",\"S8_2\"]},\n",
    "                     {'name':'S202_m','programs':[\"S202_1\",\"S202_2\"]},\n",
    "                     {'name':'S236_m','programs':[\"S236_1\",\"S236_2\"]},\n",
    "                     {'name':'FHA_m','programs':[\"FHA_1\",\"FHA_2\"]},\n",
    "                     {'name':'LIHTC_m','programs':[\"LIHTC_1\",\"LIHTC_2\"]}]:\n",
    "    program = program_info['name']\n",
    "    print \"https://tiles.earthtime.org/preservationdatabase/pgh_current_%s_2018.csv\"%(program)\n",
    "    print \"https://tiles.earthtime.org/preservationdatabase/pgh_expiring_%s_2018.csv\"%(program)\n",
    "    print \"https://tiles.earthtime.org/preservationdatabase/pgh_expired_%s_2018.csv\"%(program)\n",
    "    print \"https://tiles.earthtime.org/preservationdatabase/pgh_total_%s_2018.csv\"%(program)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public housing history with Jala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Residence Name</th>\n",
       "      <th>LocID</th>\n",
       "      <th>Own type</th>\n",
       "      <th>Mgmt type</th>\n",
       "      <th>Address</th>\n",
       "      <th>Size</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Addision Terrace</td>\n",
       "      <td>Addison</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>2100 Elmore Street, Pittsburgh, PA</td>\n",
       "      <td>736</td>\n",
       "      <td>1940</td>\n",
       "      <td>2011</td>\n",
       "      <td>40.443704</td>\n",
       "      <td>-79.976888</td>\n",
       "      <td>Put back 400 units, leaving over 300 families displaced; opened by Franklin Roosevelt; AKA \"Elmore Square\" and \"Bentley Drive\"; moved out families between 2011 and 2013; demolition completed in 2012; rebuilt in 2013 (fewer units)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>Allegheny Dwellings Belleau</td>\n",
       "      <td>AlleghenyDwellingsB</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>1710 Belleau Dr, Pittsburgh, PA 15212</td>\n",
       "      <td>174</td>\n",
       "      <td>1939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.460846</td>\n",
       "      <td>-80.006823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>Allegheny Dwellings Sandusky</td>\n",
       "      <td>AlleghenyDwellingsS</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>1710 Belleau Dr, Pittsburgh, PA 15212</td>\n",
       "      <td>97</td>\n",
       "      <td>1939</td>\n",
       "      <td>2018</td>\n",
       "      <td>40.459703</td>\n",
       "      <td>-80.006147</td>\n",
       "      <td>They tore these down in 2018.  Trek Development (private) are now rebuilding 65 town houses (was 97 before).  They will be privately owned and managed.  Housing Authority plans to move people down from Belleau when construction is done.  There are stipulations: job for 12 consecutive months, in ...</td>\n",
       "      <td>https://triblive.com/local/allegheny/13576448-74/housing-authority-of-pittsburgh-converting-allegheny-dwellings-to-mixed-income-community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Allequippa Terrace</td>\n",
       "      <td>Allequippa</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>280 Burrows St, Pittsburgh, PA 15213</td>\n",
       "      <td>1851</td>\n",
       "      <td>1938</td>\n",
       "      <td>1995</td>\n",
       "      <td>40.439690</td>\n",
       "      <td>-79.970037</td>\n",
       "      <td>18-26 units per block; first batch of townhomes started replacing it in 1995; don't know when demolition happened</td>\n",
       "      <td>https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Oak Hill</td>\n",
       "      <td>Allequippa</td>\n",
       "      <td>private</td>\n",
       "      <td>private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639</td>\n",
       "      <td>1995</td>\n",
       "      <td>2011</td>\n",
       "      <td>40.439690</td>\n",
       "      <td>-79.970037</td>\n",
       "      <td>Was Allequippa Terrace, rebuilt as privately owned mixed income townhouses</td>\n",
       "      <td>https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Oak Hill</td>\n",
       "      <td>Allequippa</td>\n",
       "      <td>private</td>\n",
       "      <td>private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>725</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.439690</td>\n",
       "      <td>-79.970037</td>\n",
       "      <td>Was Allequippa Terrace, rebuilt as privately owned mixed income townhouses</td>\n",
       "      <td>https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>Arlington Heights</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660</td>\n",
       "      <td>1942</td>\n",
       "      <td>1991</td>\n",
       "      <td>40.416563</td>\n",
       "      <td>-79.961760</td>\n",
       "      <td>Arlington Heights, built in 1942, still retains 143 occupied housing units. But much of its 82 acres, too, is a ghost town now — the result of a \"downsizing plan\" implemented in the late 1990s and early 2000s.</td>\n",
       "      <td>https://www.pghcitypaper.com/pittsburgh/up-on-the-farm-could-large-urban-farms-be-the-future-of-two-hilltop-zombie-towns/Content?oid=1688865</td>\n",
       "      <td>1400 people in 1990, dropped to 238 (units unknown) ~1999 (lost 84% of people)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>Arlington Heights</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1991</td>\n",
       "      <td>1999</td>\n",
       "      <td>40.416563</td>\n",
       "      <td>-79.961760</td>\n",
       "      <td>Arlington Heights, built in 1942, still retains 143 occupied housing units. But much of its 82 acres, too, is a ghost town now — the result of a \"downsizing plan\" implemented in the late 1990s and early 2000s.</td>\n",
       "      <td>https://www.pghcitypaper.com/pittsburgh/up-on-the-farm-could-large-urban-farms-be-the-future-of-two-hilltop-zombie-towns/Content?oid=1688865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "      <td>Arlington Heights</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.416563</td>\n",
       "      <td>-79.961760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>Auburn Towers</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>6290 Auburn Street, Pittsburgh, PA</td>\n",
       "      <td>286</td>\n",
       "      <td>1960</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.464694</td>\n",
       "      <td>-79.917416</td>\n",
       "      <td>10 story high rise</td>\n",
       "      <td>http://www.post-gazette.com/local/neighborhoods/2008/07/26/Larimer-s-Auburn-Towers-will-fall-on-Monday/stories/200807260145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Broadhead Manor</td>\n",
       "      <td>Broadhead</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364</td>\n",
       "      <td>1953</td>\n",
       "      <td>1996</td>\n",
       "      <td>40.449467</td>\n",
       "      <td>-80.084164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12</td>\n",
       "      <td>http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>Broadhead Manor</td>\n",
       "      <td>Broadhead</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>1996</td>\n",
       "      <td>1998</td>\n",
       "      <td>40.449467</td>\n",
       "      <td>-80.084164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12</td>\n",
       "      <td>http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>Broadhead Manor</td>\n",
       "      <td>Broadhead</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>1998</td>\n",
       "      <td>2004</td>\n",
       "      <td>40.449467</td>\n",
       "      <td>-80.084164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12</td>\n",
       "      <td>http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>East Mall</td>\n",
       "      <td>EastMall</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>(In intersection, there was a tunnel below it)</td>\n",
       "      <td>160</td>\n",
       "      <td>1960</td>\n",
       "      <td>2005</td>\n",
       "      <td>40.462614</td>\n",
       "      <td>-79.927153</td>\n",
       "      <td>17 stories</td>\n",
       "      <td>\"[Plan] is to demolish the 17-story, 160-unit East Mall apartment complex that straddles Penn Avenue\"</td>\n",
       "      <td>http://old.post-gazette.com/businessnews/20010111eliberty2.asp</td>\n",
       "      <td>5/5/2005: From 1:45 to 6 p.m. tomorrow, hundreds of people will use the slingshot to create a new piece of public art while celebrating the demise of East Mall, a high-rise that straddles Penn Avenue and has a date with a demolition crew in the next two weeks.</td>\n",
       "      <td>http://www.post-gazette.com/local/city/2005/05/05/Doomed-East-Liberty-high-rise-to-get-slingshot-fired-paint-job/stories/200505050281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>Francis Court</td>\n",
       "      <td>Francis</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>1980</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.450068</td>\n",
       "      <td>-79.969696</td>\n",
       "      <td>Jala guessing closed ~2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Liberty Park High Rise</td>\n",
       "      <td>LibPKHr</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>(across from Target)</td>\n",
       "      <td>158</td>\n",
       "      <td>1960</td>\n",
       "      <td>2007</td>\n",
       "      <td>40.461649</td>\n",
       "      <td>-79.921189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Mall and Liberty Park, a complex of low-slung homes and one high-rise, have come down. The area's only remaining high-rise, Penn Circle, will be vacated by the end of the year. So far, only the Liberty Park site has been rebuilt: It is now a 124-unit mixed-income rental development. Roughly...</td>\n",
       "      <td>https://www.pghcitypaper.com/pittsburgh/at-liberty-to-speak/Content?oid=1339275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Liberty Park Scattered</td>\n",
       "      <td>LibPkSc</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>(scattered sites, between Centre, E Liberty Blvd, Larimer Ave, and Station St., also a high rise)</td>\n",
       "      <td>174</td>\n",
       "      <td>1960</td>\n",
       "      <td>2010</td>\n",
       "      <td>40.463387</td>\n",
       "      <td>-79.920135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>Manchester Public Hope VI</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>1990</td>\n",
       "      <td>1996</td>\n",
       "      <td>40.456336</td>\n",
       "      <td>-80.024446</td>\n",
       "      <td>Scattered site: Nixon St -&gt; Page St -&gt; Allegheny -&gt; Along tracks back to Nixon St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>Manchester Private Hope VI</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>public</td>\n",
       "      <td>private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>1996</td>\n",
       "      <td>2016</td>\n",
       "      <td>40.456336</td>\n",
       "      <td>-80.024446</td>\n",
       "      <td>Pennrose started private management, land still owned by Housing Authority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "      <td>Manchester Public Hope VI</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.456336</td>\n",
       "      <td>-80.024446</td>\n",
       "      <td>Jala and tenants got Housing Authority to take it back (http://www.post-gazette.com/local/city/2016/06/23/Twenty-years-after-Hope-VI-debuted-as-privately-owned-public-housing-in-Manchester-the-housing-authority-has-to-step-in-to-rescue-it/stories/201606230026)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Northview Heights</td>\n",
       "      <td>Northview</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>1962</td>\n",
       "      <td>2010</td>\n",
       "      <td>40.475306</td>\n",
       "      <td>-80.001395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Northview_Heights_(Pittsburgh)</td>\n",
       "      <td>http://www.city-data.com/forum/pittsburgh/2817902-neighborhood-week-northview-heights.html</td>\n",
       "      <td>http://northsidehistory.org/a-brief-history-of-northview-heights-1960s/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Northview Heights</td>\n",
       "      <td>Northview</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723</td>\n",
       "      <td>2010</td>\n",
       "      <td>2017</td>\n",
       "      <td>40.475306</td>\n",
       "      <td>-80.001395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Northview Heights</td>\n",
       "      <td>Northview</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>455</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.475306</td>\n",
       "      <td>-80.001395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Northview Heights Highrise</td>\n",
       "      <td>Northview HR</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>1962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.477768</td>\n",
       "      <td>-79.999773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://northsidehistory.org/a-brief-history-of-northview-heights-1960s/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Penn Circle Towers</td>\n",
       "      <td>PennC</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>(Exactly where Target is now)</td>\n",
       "      <td>326</td>\n",
       "      <td>1969</td>\n",
       "      <td>2009</td>\n",
       "      <td>40.460917</td>\n",
       "      <td>-79.921356</td>\n",
       "      <td>20 stories</td>\n",
       "      <td>Looks like the one where Target is actually \"Penn Circle Tower\".  It was demolished in 2009.</td>\n",
       "      <td>https://triblive.com/x/valleynewsdispatch/s_625585.html</td>\n",
       "      <td>Was bought by \"Community Builders Inc., a Boston nonprofit\" in 2001. \"Penn Circle Tower, another 20-story high-rise along Penn Avenue, would probably remain but with improvements.\" ... The changes require the approval of the U.S. Department of Housing and Urban Development, which subsidizes most...</td>\n",
       "      <td>http://old.post-gazette.com/businessnews/20010111eliberty2.asp</td>\n",
       "      <td>[As of 2014] Penn Circle South and Penn Circle East are now both a part of Centre Avenue, allowing Centre to run uninterrupted from its Downtown origin until it hits East Liberty Boulevard.; Penn Circle West has been reabsorbed by Euclid Avenue. North Euclid Avenue now runs from the north in Hig...</td>\n",
       "      <td>https://www.nextpittsburgh.com/neighborhoods/east-liberty/penn-circle-east-liberty-streets-renamed/</td>\n",
       "      <td>Map of where Penn Circle used to be</td>\n",
       "      <td>https://www.wtae.com/article/penn-circle-quadrant-in-east-liberty-getting-name-change-1/7465723</td>\n",
       "      <td>Since the early 2000s, the wrecking ball has claimed not only the roughly 650 affordable units in Federal American Properties, but other smaller developments as well.  During the same time period, hundreds of replacement units have been built, yet heated disagreements persist about whether it su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>St. Clair Village</td>\n",
       "      <td>StClair</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680</td>\n",
       "      <td>1949</td>\n",
       "      <td>2010</td>\n",
       "      <td>40.409240</td>\n",
       "      <td>-79.973939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/St._Clair_Village</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>Westgate Village</td>\n",
       "      <td>Westgate</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434</td>\n",
       "      <td>1960</td>\n",
       "      <td>2001</td>\n",
       "      <td>40.450282</td>\n",
       "      <td>-80.076926</td>\n",
       "      <td>Shortly after Broadhead Manor was slated for demolition, the neighboring development of Westgate Village was in its death throes. The privately owned Section 8 development with 434 units is now vacant and patrolled by private security officers.</td>\n",
       "      <td>http://www.post-gazette.com/local/city/2004/10/16/Housing-Authority-weighs-fate-of-Broadhead-Manor/stories/200410160140</td>\n",
       "      <td>Was renamed to Emerald Gardens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>Emerald Gardens</td>\n",
       "      <td>Westgate</td>\n",
       "      <td>private</td>\n",
       "      <td>private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.450282</td>\n",
       "      <td>-80.076926</td>\n",
       "      <td>Last year, it purchased the former Westgate Village housing projects in Fairywood. First New Jersey plans to invest $15 million in the 436-unit complex, which has been empty for about five years, said project manger Hirsch Chinn.A gated security entrance for the renamed Emerald Gardens is under ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://triblive.com/x/archive/1329595-74/archive-story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>Whiteside Road</td>\n",
       "      <td>Whiteside</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>1949</td>\n",
       "      <td>2002</td>\n",
       "      <td>40.449092</td>\n",
       "      <td>-79.979206</td>\n",
       "      <td>Part of Bedford Dwellings; that road is now called memory ln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                Residence Name                LocID Own type  \\\n",
       "0       4              Addision Terrace              Addison   public   \n",
       "1      13   Allegheny Dwellings Belleau  AlleghenyDwellingsB   public   \n",
       "2      14  Allegheny Dwellings Sandusky  AlleghenyDwellingsS   public   \n",
       "3       7            Allequippa Terrace           Allequippa   public   \n",
       "4       8                      Oak Hill           Allequippa  private   \n",
       "5       9                      Oak Hill           Allequippa  private   \n",
       "6      26             Arlington Heights            Arlington   public   \n",
       "7      27             Arlington Heights            Arlington   public   \n",
       "8      28             Arlington Heights            Arlington   public   \n",
       "9      15                 Auburn Towers               Auburn   public   \n",
       "10     16               Broadhead Manor            Broadhead   public   \n",
       "11     17               Broadhead Manor            Broadhead   public   \n",
       "12     18               Broadhead Manor            Broadhead   public   \n",
       "13      0                     East Mall             EastMall   public   \n",
       "14     25                 Francis Court              Francis   public   \n",
       "15      2        Liberty Park High Rise              LibPKHr   public   \n",
       "16      1        Liberty Park Scattered              LibPkSc   public   \n",
       "17     10     Manchester Public Hope VI           Manchester   public   \n",
       "18     11    Manchester Private Hope VI           Manchester   public   \n",
       "19     12     Manchester Public Hope VI           Manchester   public   \n",
       "20     21             Northview Heights            Northview   public   \n",
       "21     22             Northview Heights            Northview   public   \n",
       "22     23             Northview Heights            Northview   public   \n",
       "23     24    Northview Heights Highrise         Northview HR   public   \n",
       "24      3            Penn Circle Towers                PennC   public   \n",
       "25      6             St. Clair Village              StClair   public   \n",
       "26     19              Westgate Village             Westgate   public   \n",
       "27     20               Emerald Gardens             Westgate  private   \n",
       "28      5                Whiteside Road            Whiteside   public   \n",
       "\n",
       "   Mgmt type  \\\n",
       "0     public   \n",
       "1     public   \n",
       "2     public   \n",
       "3     public   \n",
       "4    private   \n",
       "5    private   \n",
       "6     public   \n",
       "7     public   \n",
       "8     public   \n",
       "9     public   \n",
       "10    public   \n",
       "11    public   \n",
       "12    public   \n",
       "13    public   \n",
       "14    public   \n",
       "15    public   \n",
       "16    public   \n",
       "17    public   \n",
       "18   private   \n",
       "19    public   \n",
       "20    public   \n",
       "21    public   \n",
       "22    public   \n",
       "23    public   \n",
       "24    public   \n",
       "25    public   \n",
       "26    public   \n",
       "27   private   \n",
       "28    public   \n",
       "\n",
       "                                                                                              Address  \\\n",
       "0                                                                  2100 Elmore Street, Pittsburgh, PA   \n",
       "1                                                               1710 Belleau Dr, Pittsburgh, PA 15212   \n",
       "2                                                               1710 Belleau Dr, Pittsburgh, PA 15212   \n",
       "3                                                                280 Burrows St, Pittsburgh, PA 15213   \n",
       "4                                                                                                 NaN   \n",
       "5                                                                                                 NaN   \n",
       "6                                                                                                 NaN   \n",
       "7                                                                                                 NaN   \n",
       "8                                                                                                 NaN   \n",
       "9                                                                  6290 Auburn Street, Pittsburgh, PA   \n",
       "10                                                                                                NaN   \n",
       "11                                                                                                NaN   \n",
       "12                                                                                                NaN   \n",
       "13                                                     (In intersection, there was a tunnel below it)   \n",
       "14                                                                                                NaN   \n",
       "15                                                                               (across from Target)   \n",
       "16  (scattered sites, between Centre, E Liberty Blvd, Larimer Ave, and Station St., also a high rise)   \n",
       "17                                                                                                NaN   \n",
       "18                                                                                                NaN   \n",
       "19                                                                                                NaN   \n",
       "20                                                                                                NaN   \n",
       "21                                                                                                NaN   \n",
       "22                                                                                                NaN   \n",
       "23                                                                                                NaN   \n",
       "24                                                                      (Exactly where Target is now)   \n",
       "25                                                                                                NaN   \n",
       "26                                                                                                NaN   \n",
       "27                                                                                                NaN   \n",
       "28                                                                                                NaN   \n",
       "\n",
       "    Size Start   End   Latitude  Longitude  \\\n",
       "0    736  1940  2011  40.443704 -79.976888   \n",
       "1    174  1939   NaN  40.460846 -80.006823   \n",
       "2     97  1939  2018  40.459703 -80.006147   \n",
       "3   1851  1938  1995  40.439690 -79.970037   \n",
       "4    639  1995  2011  40.439690 -79.970037   \n",
       "5    725  2011   NaN  40.439690 -79.970037   \n",
       "6    660  1942  1991  40.416563 -79.961760   \n",
       "7    200  1991  1999  40.416563 -79.961760   \n",
       "8    143  1999   NaN  40.416563 -79.961760   \n",
       "9    286  1960  2008  40.464694 -79.917416   \n",
       "10   364  1953  1996  40.449467 -80.084164   \n",
       "11   250  1996  1998  40.449467 -80.084164   \n",
       "12    64  1998  2004  40.449467 -80.084164   \n",
       "13   160  1960  2005  40.462614 -79.927153   \n",
       "14    85  1980  2008  40.450068 -79.969696   \n",
       "15   158  1960  2007  40.461649 -79.921189   \n",
       "16   174  1960  2010  40.463387 -79.920135   \n",
       "17    86  1990  1996  40.456336 -80.024446   \n",
       "18    86  1996  2016  40.456336 -80.024446   \n",
       "19    86  2016   NaN  40.456336 -80.024446   \n",
       "20   999  1962  2010  40.475306 -80.001395   \n",
       "21   723  2010  2017  40.475306 -80.001395   \n",
       "22   455  2017   NaN  40.475306 -80.001395   \n",
       "23    87  1962   NaN  40.477768 -79.999773   \n",
       "24   326  1969  2009  40.460917 -79.921356   \n",
       "25   680  1949  2010  40.409240 -79.973939   \n",
       "26   434  1960  2001  40.450282 -80.076926   \n",
       "27   436  2006   NaN  40.450282 -80.076926   \n",
       "28   300  1949  2002  40.449092 -79.979206   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          Notes  \\\n",
       "0                                                                         Put back 400 units, leaving over 300 families displaced; opened by Franklin Roosevelt; AKA \"Elmore Square\" and \"Bentley Drive\"; moved out families between 2011 and 2013; demolition completed in 2012; rebuilt in 2013 (fewer units)   \n",
       "1                                                                                                                                                                                                                                                                                                           NaN   \n",
       "2   They tore these down in 2018.  Trek Development (private) are now rebuilding 65 town houses (was 97 before).  They will be privately owned and managed.  Housing Authority plans to move people down from Belleau when construction is done.  There are stipulations: job for 12 consecutive months, in ...   \n",
       "3                                                                                                                                                                                             18-26 units per block; first batch of townhomes started replacing it in 1995; don't know when demolition happened   \n",
       "4                                                                                                                                                                                                                                    Was Allequippa Terrace, rebuilt as privately owned mixed income townhouses   \n",
       "5                                                                                                                                                                                                                                    Was Allequippa Terrace, rebuilt as privately owned mixed income townhouses   \n",
       "6                                                                                             Arlington Heights, built in 1942, still retains 143 occupied housing units. But much of its 82 acres, too, is a ghost town now — the result of a \"downsizing plan\" implemented in the late 1990s and early 2000s.   \n",
       "7                                                                                             Arlington Heights, built in 1942, still retains 143 occupied housing units. But much of its 82 acres, too, is a ghost town now — the result of a \"downsizing plan\" implemented in the late 1990s and early 2000s.   \n",
       "8                                                                                                                                                                                                                                                                                                           NaN   \n",
       "9                                                                                                                                                                                                                                                                                            10 story high rise   \n",
       "10                                                                                                                                                                                                                                                                                                          NaN   \n",
       "11                                                                                                                                                                                                                                                                                                          NaN   \n",
       "12                                                                                                                                                                                                                                                                                                          NaN   \n",
       "13                                                                                                                                                                                                                                                                                                   17 stories   \n",
       "14                                                                                                                                                                                                                                                                                   Jala guessing closed ~2003   \n",
       "15                                                                                                                                                                                                                                                                                                          NaN   \n",
       "16                                                                                                                                                                                                                                                                                                          NaN   \n",
       "17                                                                                                                                                                                                                           Scattered site: Nixon St -> Page St -> Allegheny -> Along tracks back to Nixon St.   \n",
       "18                                                                                                                                                                                                                                   Pennrose started private management, land still owned by Housing Authority   \n",
       "19                                         Jala and tenants got Housing Authority to take it back (http://www.post-gazette.com/local/city/2016/06/23/Twenty-years-after-Hope-VI-debuted-as-privately-owned-public-housing-in-Manchester-the-housing-authority-has-to-step-in-to-rescue-it/stories/201606230026)   \n",
       "20                                                                                                                                                                                                                                                                                                          NaN   \n",
       "21                                                                                                                                                                                                                                                                                                          NaN   \n",
       "22                                                                                                                                                                                                                                                                                                          NaN   \n",
       "23                                                                                                                                                                                                                                                                                                          NaN   \n",
       "24                                                                                                                                                                                                                                                                                                   20 stories   \n",
       "25                                                                                                                                                                                                                                                                                                          NaN   \n",
       "26                                                         Shortly after Broadhead Manor was slated for demolition, the neighboring development of Westgate Village was in its death throes. The privately owned Section 8 development with 434 units is now vacant and patrolled by private security officers.   \n",
       "27  Last year, it purchased the former Westgate Village housing projects in Fairywood. First New Jersey plans to invest $15 million in the 436-unit complex, which has been empty for about five years, said project manger Hirsch Chinn.A gated security entrance for the renamed Emerald Gardens is under ...   \n",
       "28                                                                                                                                                                                                                                                 Part of Bedford Dwellings; that road is now called memory ln   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    Unnamed: 11  \\\n",
       "0                                                                                                                                                                                                                                                                                                           NaN   \n",
       "1                                                                                                                                                                                                                                                                                                           NaN   \n",
       "2                                                                                                                                                                     https://triblive.com/local/allegheny/13576448-74/housing-authority-of-pittsburgh-converting-allegheny-dwellings-to-mixed-income-community   \n",
       "3                                                                                                                                                                                                    https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/   \n",
       "4                                                                                                                                                                                                    https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/   \n",
       "5                                                                                                                                                                                                    https://newpittsburghcourieronline.com/2011/08/17/final-phase-of-allequippa-terrace-to-oak-hill-completed/   \n",
       "6                                                                                                                                                                  https://www.pghcitypaper.com/pittsburgh/up-on-the-farm-could-large-urban-farms-be-the-future-of-two-hilltop-zombie-towns/Content?oid=1688865   \n",
       "7                                                                                                                                                                  https://www.pghcitypaper.com/pittsburgh/up-on-the-farm-could-large-urban-farms-be-the-future-of-two-hilltop-zombie-towns/Content?oid=1688865   \n",
       "8                                                                                                                                                                                                                                                                                                           NaN   \n",
       "9                                                                                                                                                                                   http://www.post-gazette.com/local/neighborhoods/2008/07/26/Larimer-s-Auburn-Towers-will-fall-on-Monday/stories/200807260145   \n",
       "10                                                                                                                                                                                                                                     https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12   \n",
       "11                                                                                                                                                                                                                                     https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12   \n",
       "12                                                                                                                                                                                                                                     https://historicpittsburgh.org/islandora/object/pitt:MSP285.B012.F13.I12   \n",
       "13                                                                                                                                                                                                        \"[Plan] is to demolish the 17-story, 160-unit East Mall apartment complex that straddles Penn Avenue\"   \n",
       "14                                                                                                                                                                                                                                                                                                          NaN   \n",
       "15  East Mall and Liberty Park, a complex of low-slung homes and one high-rise, have come down. The area's only remaining high-rise, Penn Circle, will be vacated by the end of the year. So far, only the Liberty Park site has been rebuilt: It is now a 124-unit mixed-income rental development. Roughly...   \n",
       "16                                                                                                                                                                                                                                                                                                          NaN   \n",
       "17                                                                                                                                                                                                                                                                                                          NaN   \n",
       "18                                                                                                                                                                                                                                                                                                          NaN   \n",
       "19                                                                                                                                                                                                                                                                                                          NaN   \n",
       "20                                                                                                                                                                                                                                                 https://en.wikipedia.org/wiki/Northview_Heights_(Pittsburgh)   \n",
       "21                                                                                                                                                                                                                                                                                                          NaN   \n",
       "22                                                                                                                                                                                                                                                                                                          NaN   \n",
       "23                                                                                                                                                                                                                                      http://northsidehistory.org/a-brief-history-of-northview-heights-1960s/   \n",
       "24                                                                                                                                                                                                                 Looks like the one where Target is actually \"Penn Circle Tower\".  It was demolished in 2009.   \n",
       "25                                                                                                                                                                                                                                                              https://en.wikipedia.org/wiki/St._Clair_Village   \n",
       "26                                                                                                                                                                                      http://www.post-gazette.com/local/city/2004/10/16/Housing-Authority-weighs-fate-of-Broadhead-Manor/stories/200410160140   \n",
       "27                                                                                                                                                                                                                                                                                                          NaN   \n",
       "28                                                                                                                                                                                                                                                                                                          NaN   \n",
       "\n",
       "                                                                                      Unnamed: 12  \\\n",
       "0                                                                                             NaN   \n",
       "1                                                                                             NaN   \n",
       "2                                                                                             NaN   \n",
       "3                                                                                             NaN   \n",
       "4                                                                                             NaN   \n",
       "5                                                                                             NaN   \n",
       "6                  1400 people in 1990, dropped to 238 (units unknown) ~1999 (lost 84% of people)   \n",
       "7                                                                                             NaN   \n",
       "8                                                                                             NaN   \n",
       "9                                                                                             NaN   \n",
       "10  http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3   \n",
       "11  http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3   \n",
       "12  http://www.city-data.com/forum/pittsburgh/296658-brodhead-manor-westgate-2.html#ixzz5UNqxqeV3   \n",
       "13                                 http://old.post-gazette.com/businessnews/20010111eliberty2.asp   \n",
       "14                                                                                            NaN   \n",
       "15                https://www.pghcitypaper.com/pittsburgh/at-liberty-to-speak/Content?oid=1339275   \n",
       "16                                                                                            NaN   \n",
       "17                                                                                            NaN   \n",
       "18                                                                                            NaN   \n",
       "19                                                                                            NaN   \n",
       "20     http://www.city-data.com/forum/pittsburgh/2817902-neighborhood-week-northview-heights.html   \n",
       "21                                                                                            NaN   \n",
       "22                                                                                            NaN   \n",
       "23                                                                                            NaN   \n",
       "24                                        https://triblive.com/x/valleynewsdispatch/s_625585.html   \n",
       "25                                                                                            NaN   \n",
       "26                                                                 Was renamed to Emerald Gardens   \n",
       "27                                        https://triblive.com/x/archive/1329595-74/archive-story   \n",
       "28                                                                                            NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    Unnamed: 13  \\\n",
       "0                                                                                                                                                                                                                                                                                                           NaN   \n",
       "1                                                                                                                                                                                                                                                                                                           NaN   \n",
       "2                                                                                                                                                                                                                                                                                                           NaN   \n",
       "3                                                                                                                                                                                                                                                                                                           NaN   \n",
       "4                                                                                                                                                                                                                                                                                                           NaN   \n",
       "5                                                                                                                                                                                                                                                                                                           NaN   \n",
       "6                                                                                                                                                                                                                                                                                                           NaN   \n",
       "7                                                                                                                                                                                                                                                                                                           NaN   \n",
       "8                                                                                                                                                                                                                                                                                                           NaN   \n",
       "9                                                                                                                                                                                                                                                                                                           NaN   \n",
       "10                                                                                                                                                                                                                                                                                                          NaN   \n",
       "11                                                                                                                                                                                                                                                                                                          NaN   \n",
       "12                                                                                                                                                                                                                                                                                                          NaN   \n",
       "13                                         5/5/2005: From 1:45 to 6 p.m. tomorrow, hundreds of people will use the slingshot to create a new piece of public art while celebrating the demise of East Mall, a high-rise that straddles Penn Avenue and has a date with a demolition crew in the next two weeks.   \n",
       "14                                                                                                                                                                                                                                                                                                          NaN   \n",
       "15                                                                                                                                                                                                                                                                                                          NaN   \n",
       "16                                                                                                                                                                                                                                                                                                          NaN   \n",
       "17                                                                                                                                                                                                                                                                                                          NaN   \n",
       "18                                                                                                                                                                                                                                                                                                          NaN   \n",
       "19                                                                                                                                                                                                                                                                                                          NaN   \n",
       "20                                                                                                                                                                                                                                      http://northsidehistory.org/a-brief-history-of-northview-heights-1960s/   \n",
       "21                                                                                                                                                                                                                                                                                                          NaN   \n",
       "22                                                                                                                                                                                                                                                                                                          NaN   \n",
       "23                                                                                                                                                                                                                                                                                                          NaN   \n",
       "24  Was bought by \"Community Builders Inc., a Boston nonprofit\" in 2001. \"Penn Circle Tower, another 20-story high-rise along Penn Avenue, would probably remain but with improvements.\" ... The changes require the approval of the U.S. Department of Housing and Urban Development, which subsidizes most...   \n",
       "25                                                                                                                                                                                                                                                                                                          NaN   \n",
       "26                                                                                                                                                                                                                                                                                                          NaN   \n",
       "27                                                                                                                                                                                                                                                                                                          NaN   \n",
       "28                                                                                                                                                                                                                                                                                                          NaN   \n",
       "\n",
       "                                                                                                                              Unnamed: 14  \\\n",
       "0                                                                                                                                     NaN   \n",
       "1                                                                                                                                     NaN   \n",
       "2                                                                                                                                     NaN   \n",
       "3                                                                                                                                     NaN   \n",
       "4                                                                                                                                     NaN   \n",
       "5                                                                                                                                     NaN   \n",
       "6                                                                                                                                     NaN   \n",
       "7                                                                                                                                     NaN   \n",
       "8                                                                                                                                     NaN   \n",
       "9                                                                                                                                     NaN   \n",
       "10                                                                                                                                    NaN   \n",
       "11                                                                                                                                    NaN   \n",
       "12                                                                                                                                    NaN   \n",
       "13  http://www.post-gazette.com/local/city/2005/05/05/Doomed-East-Liberty-high-rise-to-get-slingshot-fired-paint-job/stories/200505050281   \n",
       "14                                                                                                                                    NaN   \n",
       "15                                                                                                                                    NaN   \n",
       "16                                                                                                                                    NaN   \n",
       "17                                                                                                                                    NaN   \n",
       "18                                                                                                                                    NaN   \n",
       "19                                                                                                                                    NaN   \n",
       "20                                                                                                                                    NaN   \n",
       "21                                                                                                                                    NaN   \n",
       "22                                                                                                                                    NaN   \n",
       "23                                                                                                                                    NaN   \n",
       "24                                                                         http://old.post-gazette.com/businessnews/20010111eliberty2.asp   \n",
       "25                                                                                                                                    NaN   \n",
       "26                                                                                                                                    NaN   \n",
       "27                                                                                                                                    NaN   \n",
       "28                                                                                                                                    NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    Unnamed: 15  \\\n",
       "0                                                                                                                                                                                                                                                                                                           NaN   \n",
       "1                                                                                                                                                                                                                                                                                                           NaN   \n",
       "2                                                                                                                                                                                                                                                                                                           NaN   \n",
       "3                                                                                                                                                                                                                                                                                                           NaN   \n",
       "4                                                                                                                                                                                                                                                                                                           NaN   \n",
       "5                                                                                                                                                                                                                                                                                                           NaN   \n",
       "6                                                                                                                                                                                                                                                                                                           NaN   \n",
       "7                                                                                                                                                                                                                                                                                                           NaN   \n",
       "8                                                                                                                                                                                                                                                                                                           NaN   \n",
       "9                                                                                                                                                                                                                                                                                                           NaN   \n",
       "10                                                                                                                                                                                                                                                                                                          NaN   \n",
       "11                                                                                                                                                                                                                                                                                                          NaN   \n",
       "12                                                                                                                                                                                                                                                                                                          NaN   \n",
       "13                                                                                                                                                                                                                                                                                                          NaN   \n",
       "14                                                                                                                                                                                                                                                                                                          NaN   \n",
       "15                                                                                                                                                                                                                                                                                                          NaN   \n",
       "16                                                                                                                                                                                                                                                                                                          NaN   \n",
       "17                                                                                                                                                                                                                                                                                                          NaN   \n",
       "18                                                                                                                                                                                                                                                                                                          NaN   \n",
       "19                                                                                                                                                                                                                                                                                                          NaN   \n",
       "20                                                                                                                                                                                                                                                                                                          NaN   \n",
       "21                                                                                                                                                                                                                                                                                                          NaN   \n",
       "22                                                                                                                                                                                                                                                                                                          NaN   \n",
       "23                                                                                                                                                                                                                                                                                                          NaN   \n",
       "24  [As of 2014] Penn Circle South and Penn Circle East are now both a part of Centre Avenue, allowing Centre to run uninterrupted from its Downtown origin until it hits East Liberty Boulevard.; Penn Circle West has been reabsorbed by Euclid Avenue. North Euclid Avenue now runs from the north in Hig...   \n",
       "25                                                                                                                                                                                                                                                                                                          NaN   \n",
       "26                                                                                                                                                                                                                                                                                                          NaN   \n",
       "27                                                                                                                                                                                                                                                                                                          NaN   \n",
       "28                                                                                                                                                                                                                                                                                                          NaN   \n",
       "\n",
       "                                                                                            Unnamed: 16  \\\n",
       "0                                                                                                   NaN   \n",
       "1                                                                                                   NaN   \n",
       "2                                                                                                   NaN   \n",
       "3                                                                                                   NaN   \n",
       "4                                                                                                   NaN   \n",
       "5                                                                                                   NaN   \n",
       "6                                                                                                   NaN   \n",
       "7                                                                                                   NaN   \n",
       "8                                                                                                   NaN   \n",
       "9                                                                                                   NaN   \n",
       "10                                                                                                  NaN   \n",
       "11                                                                                                  NaN   \n",
       "12                                                                                                  NaN   \n",
       "13                                                                                                  NaN   \n",
       "14                                                                                                  NaN   \n",
       "15                                                                                                  NaN   \n",
       "16                                                                                                  NaN   \n",
       "17                                                                                                  NaN   \n",
       "18                                                                                                  NaN   \n",
       "19                                                                                                  NaN   \n",
       "20                                                                                                  NaN   \n",
       "21                                                                                                  NaN   \n",
       "22                                                                                                  NaN   \n",
       "23                                                                                                  NaN   \n",
       "24  https://www.nextpittsburgh.com/neighborhoods/east-liberty/penn-circle-east-liberty-streets-renamed/   \n",
       "25                                                                                                  NaN   \n",
       "26                                                                                                  NaN   \n",
       "27                                                                                                  NaN   \n",
       "28                                                                                                  NaN   \n",
       "\n",
       "                            Unnamed: 17  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "5                                   NaN   \n",
       "6                                   NaN   \n",
       "7                                   NaN   \n",
       "8                                   NaN   \n",
       "9                                   NaN   \n",
       "10                                  NaN   \n",
       "11                                  NaN   \n",
       "12                                  NaN   \n",
       "13                                  NaN   \n",
       "14                                  NaN   \n",
       "15                                  NaN   \n",
       "16                                  NaN   \n",
       "17                                  NaN   \n",
       "18                                  NaN   \n",
       "19                                  NaN   \n",
       "20                                  NaN   \n",
       "21                                  NaN   \n",
       "22                                  NaN   \n",
       "23                                  NaN   \n",
       "24  Map of where Penn Circle used to be   \n",
       "25                                  NaN   \n",
       "26                                  NaN   \n",
       "27                                  NaN   \n",
       "28                                  NaN   \n",
       "\n",
       "                                                                                        Unnamed: 18  \\\n",
       "0                                                                                               NaN   \n",
       "1                                                                                               NaN   \n",
       "2                                                                                               NaN   \n",
       "3                                                                                               NaN   \n",
       "4                                                                                               NaN   \n",
       "5                                                                                               NaN   \n",
       "6                                                                                               NaN   \n",
       "7                                                                                               NaN   \n",
       "8                                                                                               NaN   \n",
       "9                                                                                               NaN   \n",
       "10                                                                                              NaN   \n",
       "11                                                                                              NaN   \n",
       "12                                                                                              NaN   \n",
       "13                                                                                              NaN   \n",
       "14                                                                                              NaN   \n",
       "15                                                                                              NaN   \n",
       "16                                                                                              NaN   \n",
       "17                                                                                              NaN   \n",
       "18                                                                                              NaN   \n",
       "19                                                                                              NaN   \n",
       "20                                                                                              NaN   \n",
       "21                                                                                              NaN   \n",
       "22                                                                                              NaN   \n",
       "23                                                                                              NaN   \n",
       "24  https://www.wtae.com/article/penn-circle-quadrant-in-east-liberty-getting-name-change-1/7465723   \n",
       "25                                                                                              NaN   \n",
       "26                                                                                              NaN   \n",
       "27                                                                                              NaN   \n",
       "28                                                                                              NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    Unnamed: 19  \n",
       "0                                                                                                                                                                                                                                                                                                           NaN  \n",
       "1                                                                                                                                                                                                                                                                                                           NaN  \n",
       "2                                                                                                                                                                                                                                                                                                           NaN  \n",
       "3                                                                                                                                                                                                                                                                                                           NaN  \n",
       "4                                                                                                                                                                                                                                                                                                           NaN  \n",
       "5                                                                                                                                                                                                                                                                                                           NaN  \n",
       "6                                                                                                                                                                                                                                                                                                           NaN  \n",
       "7                                                                                                                                                                                                                                                                                                           NaN  \n",
       "8                                                                                                                                                                                                                                                                                                           NaN  \n",
       "9                                                                                                                                                                                                                                                                                                           NaN  \n",
       "10                                                                                                                                                                                                                                                                                                          NaN  \n",
       "11                                                                                                                                                                                                                                                                                                          NaN  \n",
       "12                                                                                                                                                                                                                                                                                                          NaN  \n",
       "13                                                                                                                                                                                                                                                                                                          NaN  \n",
       "14                                                                                                                                                                                                                                                                                                          NaN  \n",
       "15                                                                                                                                                                                                                                                                                                          NaN  \n",
       "16                                                                                                                                                                                                                                                                                                          NaN  \n",
       "17                                                                                                                                                                                                                                                                                                          NaN  \n",
       "18                                                                                                                                                                                                                                                                                                          NaN  \n",
       "19                                                                                                                                                                                                                                                                                                          NaN  \n",
       "20                                                                                                                                                                                                                                                                                                          NaN  \n",
       "21                                                                                                                                                                                                                                                                                                          NaN  \n",
       "22                                                                                                                                                                                                                                                                                                          NaN  \n",
       "23                                                                                                                                                                                                                                                                                                          NaN  \n",
       "24  Since the early 2000s, the wrecking ball has claimed not only the roughly 650 affordable units in Federal American Properties, but other smaller developments as well.  During the same time period, hundreds of replacement units have been built, yet heated disagreements persist about whether it su...  \n",
       "25                                                                                                                                                                                                                                                                                                          NaN  \n",
       "26                                                                                                                                                                                                                                                                                                          NaN  \n",
       "27                                                                                                                                                                                                                                                                                                          NaN  \n",
       "28                                                                                                                                                                                                                                                                                                          NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phh_path = 'https://docs-proxy.cmucreatelab.org/spreadsheets/d/1SasXUMnzGxxnaktgB1GnsA0jjEGOagEQszqiB2nxIZM/export?format=csv&gid=1721321247'\n",
    "phh_data = pandas.read_csv(phh_path, dtype={'Start':numpy.str, 'End':numpy.str})\n",
    "\n",
    "# Sort first by LocID and then by start date.  Get rid of any where LocID is empty\n",
    "phh_data_s = phh_data[~pd.isna(phh_data.LocID)].sort_values(['LocID', 'Start'], ascending=[True, True]).reset_index()\n",
    "phh_data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a map of LocID to array of row numbers into phh_data_s\n",
    "residence_map={}\n",
    "\n",
    "for i in range(0,len(phh_data_s.index)):\n",
    "    LocID=phh_data_s.iloc[i]['LocID']\n",
    "    if LocID in residence_map:\n",
    "        residence_map[LocID].append(i)\n",
    "    else:\n",
    "        residence_map[LocID]=[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Addison': [0],\n",
       " 'AlleghenyDwellingsB': [1],\n",
       " 'AlleghenyDwellingsS': [2],\n",
       " 'Allequippa': [3, 4, 5],\n",
       " 'Arlington': [6, 7, 8],\n",
       " 'Auburn': [9],\n",
       " 'Broadhead': [10, 11, 12],\n",
       " 'EastMall': [13],\n",
       " 'Francis': [14],\n",
       " 'LibPKHr': [15],\n",
       " 'LibPkSc': [16],\n",
       " 'Manchester': [17, 18, 19],\n",
       " 'Northview': [20, 21, 22],\n",
       " 'Northview HR': [23],\n",
       " 'PennC': [24],\n",
       " 'StClair': [25],\n",
       " 'Westgate': [26, 27],\n",
       " 'Whiteside': [28]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residence_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_year = arrow.now().year+2\n",
    "next_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use color map https://tiles.earthtime.org/colormaps/grey-red-yellow-green-purple.png\n",
    "current_val=3\n",
    "private_val = 4\n",
    "expiring_val=2\n",
    "expired_val=1\n",
    "\n",
    "def write_phh_csv(include_sizes, include_latlon, out_path):\n",
    "    date_range = range(1960, next_year)\n",
    "    out = open(out_path, 'w')\n",
    "    # Write out header row.  First column doesn't have a column heading, next two are lat, lon, then each year\n",
    "    latlon_str=''\n",
    "    if(include_latlon):\n",
    "        latlon_str='lat,lon,'\n",
    "    out.write(\"id,%s%s\\n\" % (latlon_str,\",\".join(map(str,date_range))))\n",
    "    \n",
    "    for LocID in residence_map.keys():\n",
    "        # Start with the earliest entry for this LocID\n",
    "        i = residence_map[LocID][0]\n",
    "        \n",
    "        # Make sure we know lat/lon\n",
    "        if(include_latlon and (pandas.isnull(phh_data_s['Latitude'][i]) or phh_data_s['Latitude'][i]=='' or\n",
    "            pandas.isnull(phh_data_s['Longitude'][i]) or phh_data_s['Longitude'][i]=='')):\n",
    "            continue\n",
    "            \n",
    "        #Output two rows, both with the same label.  First row is bubble size.  Second row is 0 - 1 for status\n",
    "        \n",
    "        # Bubble size row -- size is 20 if not set, or size if set\n",
    "        size_row=[str(phh_data_s['Residence Name'][i])]\n",
    "        if(include_latlon):\n",
    "            size_row.append(phh_data_s['Latitude'][i])\n",
    "            size_row.append(phh_data_s['Longitude'][i])\n",
    "\n",
    "        # Calculate start_year and end_year for this property.  In case that there's more than one row for this \n",
    "        # LocID, set start_year to the earliest start_year and end_year to the latest\n",
    "        # end year.  If the latest end year is NaN then it's still open today.\n",
    "        end_i = (residence_map[LocID][-1])\n",
    "        start_year = int(phh_data_s['Start'][i])\n",
    "        # In case this property is still active, set end_year to be in the future\n",
    "        end_year = next_year+1\n",
    "        if(not pd.isna(phh_data_s['End'][end_i])):\n",
    "            # We have a real end year\n",
    "            end_year = int(phh_data_s['End'][end_i])\n",
    "            \n",
    "        # Use j to keep track of which row we're processing now\n",
    "        j=i\n",
    "        for year in date_range:\n",
    "            if(year<end_year and not pd.isna(phh_data_s['End'][j]) and year >= int(phh_data_s['End'][j])):\n",
    "                # Go to the next row\n",
    "                j=j+1\n",
    "                print \"Processing %s for %d, moving to next row %d\" % (LocID, year, j)\n",
    "            #if(phh_data_s['Size'][i]!=''):\n",
    "            if(year<start_year):\n",
    "                # Not open yet, set size to zero\n",
    "                size_row.append(0)\n",
    "            elif(not pandas.isnull(phh_data_s['Size'][j]) and phh_data_s['Size'][j]!=''):\n",
    "                size_row.append(int(phh_data_s['Size'][j]))\n",
    "            else:\n",
    "                size_row.append(20)\n",
    "        \n",
    "        # Bubble color row -- value depends on status\n",
    "        color_row=[str(phh_data_s['Residence Name'][i])]\n",
    "        if(include_latlon):\n",
    "            color_row.append(phh_data_s['Latitude'][i])\n",
    "            color_row.append(phh_data_s['Longitude'][i])\n",
    "\n",
    "            \n",
    "        # Use j to keep track of which row we're processing now\n",
    "        j=i\n",
    "        for year in date_range:\n",
    "            color_val=0\n",
    "            if(year<end_year):\n",
    "                if (year >= start_year and year< end_year):\n",
    "                    if(not pd.isna(phh_data_s['End'][j]) and year >= int(phh_data_s['End'][j])):\n",
    "                        # Go to the next row\n",
    "                        j=j+1\n",
    "                        print \"Processing %s for %d, moving to next row %d\" % (LocID, year, j)\n",
    "                    # If Own type or Mgmt type is private, set color to private_val, otherwise use current_val\n",
    "                    color_val=current_val\n",
    "                    if(phh_data_s['Own type'][j]=='private' or phh_data_s['Mgmt type'][j]=='private'):\n",
    "                        color_val=private_val\n",
    "                    # If Start for this row is > year (which can happen if a property is closed down for a while)\n",
    "                    # use expired_val\n",
    "                    if(int(phh_data_s['Start'][j])>year):\n",
    "                        print \"%s %d [%s]: In gap, not open, show as expired\"%(LocID, year, j)\n",
    "                        color_val = expired_val\n",
    "                    \n",
    "                elif (year==end_year):\n",
    "                    color_val=expiring_val\n",
    "                elif (year>end_year):\n",
    "                    color_val=expired_val\n",
    "                color_row.append(color_val)\n",
    "            else:\n",
    "                color_row.append(expired_val)\n",
    "            \n",
    "        # Write both rows for this property out here if include_sizes is true.  \n",
    "        # Otherwise just do the color row\n",
    "        if(include_sizes):\n",
    "            out.write('%s\\n' % (\",\".join(map(str,size_row))))\n",
    "        out.write('%s\\n' % (\",\".join(map(str,color_row))))\n",
    "\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Allequippa for 1995, moving to next row 4\n",
      "Processing Allequippa for 2011, moving to next row 5\n",
      "Processing Allequippa for 1995, moving to next row 4\n",
      "Processing Allequippa for 2011, moving to next row 5\n",
      "Processing Westgate for 2001, moving to next row 27\n",
      "Processing Westgate for 2001, moving to next row 27\n",
      "Westgate 2001 [27]: In gap, not open, show as expired\n",
      "Westgate 2002 [27]: In gap, not open, show as expired\n",
      "Westgate 2003 [27]: In gap, not open, show as expired\n",
      "Westgate 2004 [27]: In gap, not open, show as expired\n",
      "Westgate 2005 [27]: In gap, not open, show as expired\n",
      "Processing Arlington for 1991, moving to next row 7\n",
      "Processing Arlington for 1999, moving to next row 8\n",
      "Processing Arlington for 1991, moving to next row 7\n",
      "Processing Arlington for 1999, moving to next row 8\n",
      "Processing Broadhead for 1996, moving to next row 11\n",
      "Processing Broadhead for 1998, moving to next row 12\n",
      "Processing Broadhead for 1996, moving to next row 11\n",
      "Processing Broadhead for 1998, moving to next row 12\n",
      "Processing Northview for 2010, moving to next row 21\n",
      "Processing Northview for 2017, moving to next row 22\n",
      "Processing Northview for 2010, moving to next row 21\n",
      "Processing Northview for 2017, moving to next row 22\n",
      "Processing Manchester for 1996, moving to next row 18\n",
      "Processing Manchester for 2016, moving to next row 19\n",
      "Processing Manchester for 1996, moving to next row 18\n",
      "Processing Manchester for 2016, moving to next row 19\n"
     ]
    }
   ],
   "source": [
    "write_phh_csv(True, True, \"allegheny_county/phh-v6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download File Templates for 5-year data\n",
    "\n",
    "5-year data is a 5-year average, ending in the named year.\n",
    "So the recently released ACS2016-5year actually is from 2012-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture/ACS2009_5year/2009_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2009_5year/2009_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2010_5year/2010_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2010_5year/2010_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2011_5year/2011_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2011_5year/2011_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2012_5year/2012_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2012_5year/2012_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2013_5year/2013_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2013_5year/2013_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2014_5year/2014_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2014_5year/2014_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2015_5year/2015_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2015_5year/2015_5yr_Summary_FileTemplates.zip already unzipped\n",
      "capture/ACS2016_5year/2016_5yr_Summary_FileTemplates.zip already downloaded\n",
      "capture/ACS2016_5year/2016_5yr_Summary_FileTemplates.zip already unzipped\n"
     ]
    }
   ],
   "source": [
    "#src = 'https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/2015_1yr_Summary_FileTemplates.zip'\n",
    "#dest = 'capture/ACS2015_1year/2015_1yr_Summary_FileTemplates.zip'\n",
    "#download_file(src, dest)\n",
    "#templates = unzip_file(dest)\n",
    "\n",
    "def download_file_templates(year):\n",
    "    src = 'https://www2.census.gov/programs-surveys/acs/summary_file/{year}/data/{year}_5yr_Summary_FileTemplates.zip'.format(**locals())\n",
    "\n",
    "    # Special-case 2010\n",
    "    src = src.replace('2010_5yr_Summary_File', '2010_5yr_SummaryFile')\n",
    "    \n",
    "    dest = 'capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates.zip'.format(**locals())\n",
    "    download_file(src, dest)\n",
    "    templates = unzip_file(dest)\n",
    "    \n",
    "for year in range(2009, 2017):\n",
    "    download_file_templates(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -l capture/ACS2015_1year/2015_1yr_Summary_FileTemplates/Templates | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ACS2015 5-year data (tract and block group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_year=2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture/ACS2009_5year/Tracts_Block_Groups_Only.zip already exists, skipping\n",
      "capture/ACS2010_5year/Tracts_Block_Groups_Only.zip already exists, skipping\n",
      "capture/ACS2011_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n",
      "capture/ACS2012_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n",
      "capture/ACS2013_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n",
      "capture/ACS2014_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n",
      "capture/ACS2015_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n",
      "capture/ACS2016_5year/Tracts_Block_Groups_Only.tar.gz already exists, skipping\n"
     ]
    }
   ],
   "source": [
    "def download_data(year):\n",
    "    filename = 'Tracts_Block_Groups_Only'\n",
    "    if year < 2011:\n",
    "        filename += '.zip'\n",
    "    else:\n",
    "        filename += '.tar.gz'\n",
    "    src = 'https://www2.census.gov/programs-surveys/acs/summary_file/{year}/data/5_year_entire_sf/{filename}'.format(**locals())\n",
    "    dest = 'capture/ACS{year}_5year/{filename}'.format(**locals())\n",
    "\n",
    "    if os.path.exists(dest):\n",
    "        print '{dest} already exists, skipping'.format(**locals())\n",
    "    else:\n",
    "        try:\n",
    "            os.unlink(filename)\n",
    "        except OSError:\n",
    "            pass\n",
    "        cmd = '/usr/bin/curl'\n",
    "        cmd += \" -H 'User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\"\n",
    "        cmd += ' {src}'.format(**locals())\n",
    "        cmd += ' >{dest}'.format(**locals())\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(dest))\n",
    "        except OSError:\n",
    "            pass\n",
    "        print cmd\n",
    "        subprocess_check(cmd)\n",
    "        print 'Downloaded to {dest}'.format(**locals())\n",
    "\n",
    "for year in range(2009, 2017):\n",
    "    download_data(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 rsargent rsargent 2806502508 Oct  5 07:52 capture/ACS2009_5year/Tracts_Block_Groups_Only.zip\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3369803296 Oct  5 07:59 capture/ACS2010_5year/Tracts_Block_Groups_Only.zip\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3297054880 Oct  5 08:12 capture/ACS2011_5year/Tracts_Block_Groups_Only.tar.gz\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3651813394 Oct  5 07:33 capture/ACS2012_5year/Tracts_Block_Groups_Only.tar.gz\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3769295680 Oct  5 07:45 capture/ACS2013_5year/Tracts_Block_Groups_Only.tar.gz\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3757945352 Oct  5 07:59 capture/ACS2014_5year/Tracts_Block_Groups_Only.tar.gz\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3747109902 Dec  2  2016 capture/ACS2015_5year/Tracts_Block_Groups_Only.tar.gz\r\n",
      "-rw-rw-r-- 1 rsargent rsargent 3780352044 Feb 14 15:00 capture/ACS2016_5year/Tracts_Block_Groups_Only.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l capture/ACS*/Tracts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !mkdir -p capture/ACS2005_5year\n",
    "# !mv  capture/ACS2005_5year\n",
    "#\n",
    "# !cd capture/ACS2005_5year; tar xvfz Tracts_Block_Groups_Only.tar.gz >/dev/null\n",
    "#\n",
    "# !wget --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11\" https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_entire_sf/2015_ACS_Geography_Files.zip\n",
    "#\n",
    "# !mv 2015_ACS_Geography_Files.zip capture/ACS2005_5year\n",
    "# \n",
    "# unzip_file('capture/ACS2005_5year/2015_ACS_Geography_Files.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_geography_data(year, force_regenerate=False):\n",
    "    fname = (\"{year}_ACS_Geography_Files.zip\").format(**locals())\n",
    "    cdir = (\"capture/ACS{year}_5year\").format(**locals())\n",
    "    fpath = (\"{cdir}/{fname}\").format(**locals())\n",
    "    \n",
    "    if os.path.exists(fpath) and not force_regenerate:\n",
    "        print '{fpath} already exists, skipping'.format(**locals())\n",
    "        return\n",
    "    \n",
    "    url_template = \"https://www2.census.gov/programs-surveys/acs/summary_file/{year}/data/5_year_entire_sf/{fname}\"\n",
    "    url = url_template.format(**locals())\n",
    "    !wget --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11\" $url\n",
    "    \n",
    "    !mv $fname $cdir\n",
    "    unzip_file(fpath)\n",
    "    print \"Downloaded %s to %s\" % (fname,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-02-28 22:16:08--  https://www2.census.gov/programs-surveys/acs/summary_file/2009/data/5_year_entire_sf/2009_ACS_Geography_Files.zip\n",
      "Resolving www2.census.gov (www2.census.gov)... 23.36.91.141, 2600:1408:7:291::208c, 2600:1408:7:2a5::208c\n",
      "Connecting to www2.census.gov (www2.census.gov)|23.36.91.141|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2018-02-28 22:16:09 ERROR 404: Not Found.\n",
      "\n",
      "mv: cannot stat '2009_ACS_Geography_Files.zip': No such file or directory\n",
      "Unzipping capture/ACS2009_5year/2009_ACS_Geography_Files.zip into capture/ACS2009_5year/2009_ACS_Geography_Files.tmp\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Call to subprocess_check failed with return code 9\nStandard error:\nunzip:  cannot find or open capture/ACS2009_5year/2009_ACS_Geography_Files.zip, capture/ACS2009_5year/2009_ACS_Geography_Files.zip.zip or capture/ACS2009_5year/2009_ACS_Geography_Files.zip.ZIP.\nStandard out:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-92b0ec7c920e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload_geography_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-501fcfb5e3f8>\u001b[0m in \u001b[0;36mdownload_geography_data\u001b[0;34m(year, force_regenerate)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'mv $fname $cdir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0munzip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Downloaded %s to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36munzip_file\u001b[0;34m(filename)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36msubprocess_check\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Call to subprocess_check failed with return code 9\nStandard error:\nunzip:  cannot find or open capture/ACS2009_5year/2009_ACS_Geography_Files.zip, capture/ACS2009_5year/2009_ACS_Geography_Files.zip.zip or capture/ACS2009_5year/2009_ACS_Geography_Files.zip.ZIP.\nStandard out:\n"
     ]
    }
   ],
   "source": [
    "download_geography_data(process_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_acs_5year_template(year, seqno):\n",
    "    for template in ['capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates/Seq{seqno}.xls',\n",
    "                     'capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates/{year}_5yr_Templates/Seq{seqno}.xls',\n",
    "                     'capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates/seq/Seq{seqno}.xls',\n",
    "                     'capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates/templates/Seq{seqno}.xls',\n",
    "                     'capture/ACS{year}_5year/{year}_5yr_Summary_FileTemplates/Seq%04d.xls'%(seqno)]:\n",
    "        path = template.format(**locals())\n",
    "        #print 'Checking for {path}'.format(**locals())\n",
    "        if os.path.exists(path):\n",
    "            return pandas.read_excel(path)\n",
    "    #print 'yo could not find {year}:{seqno}'.format(**locals())\n",
    "    return None\n",
    "\n",
    "def find_acs_5year_data(year, state, seqno):\n",
    "    fname = 'e%d5%s%04d000.txt' % (year, state, seqno)\n",
    "    for template in ['capture/ACS{year}_5year/group2/{fname}',\n",
    "                     'capture/ACS{year}_5year/data/tab4/sumfile/prod/2012thru2016/group2/{fname}',\n",
    "                     'capture/ACS{year}_5year/tab4/sumfile/prod/2010thru2014/group2/{fname}',\n",
    "                     'capture/ACS{year}_5year/tab4/sumfile/prod/2008thru2012/group2/{fname}',\n",
    "                     'capture/ACS{year}_5year/tab4/sumfile/prod/2006thru2010/group2/{fname}']:\n",
    "        path = template.format(**locals())\n",
    "        #print 'Checking for {path}'.format(**locals())\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    print 'Could not find {year}:{seqno} file {fname}'.format(**locals())\n",
    "    return None\n",
    "\n",
    "# Combine template header and data into pandas frame\n",
    "def read_acs_5year_data(year, state, seqno):\n",
    "    header = read_acs_5year_template(year, seqno)\n",
    "    data_fname = find_acs_5year_data(year, state, seqno)\n",
    "    if not data_fname:\n",
    "        return None\n",
    "    else:\n",
    "        data = pandas.read_csv(data_fname,\n",
    "                               index_col=False,\n",
    "                               dtype={'FILEID':numpy.str,\n",
    "                                      'FILETYPE':numpy.str,\n",
    "                                      'STUSAB':numpy.str,\n",
    "                                      'CHARITER':numpy.str,\n",
    "                                      'SEQUENCE':numpy.str,\n",
    "                                      'LOGRECNO':numpy.str},\n",
    "                               header=None,\n",
    "                               names=header.columns.values)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>FILETYPE</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>B07401_001</th>\n",
       "      <th>B07401_002</th>\n",
       "      <th>B07401_003</th>\n",
       "      <th>B07401_004</th>\n",
       "      <th>...</th>\n",
       "      <th>B07409_021</th>\n",
       "      <th>B07409_022</th>\n",
       "      <th>B07409_023</th>\n",
       "      <th>B07409_024</th>\n",
       "      <th>B07409_025</th>\n",
       "      <th>B07409_026</th>\n",
       "      <th>B07409_027</th>\n",
       "      <th>B07409_028</th>\n",
       "      <th>B07409_029</th>\n",
       "      <th>B07409_030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FILEID</td>\n",
       "      <td>FILETYPE</td>\n",
       "      <td>STUSAB</td>\n",
       "      <td>CHARITER</td>\n",
       "      <td>SEQUENCE</td>\n",
       "      <td>LOGRECNO</td>\n",
       "      <td>Population 1 year and over in the United States</td>\n",
       "      <td>Population 1 year and over in the United States% 1 to 4 years</td>\n",
       "      <td>Population 1 year and over in the United States% 5 to 17 years</td>\n",
       "      <td>Population 1 year and over in the United States% 18 and 19 years</td>\n",
       "      <td>...</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different county within same state:% High school graduate (includes equivalency)</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different county within same state:% Some college or associate's degree</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different county within same state:% Bachelor's degree</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different county within same state:% Graduate or professional degree</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:% Less than high school graduate</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:% High school graduate (includes equivalency)</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:% Some college or associate's degree</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:% Bachelor's degree</td>\n",
       "      <td>Population 25 years and over in the United States% Moved to different state:% Graduate or professional degree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FILEID  FILETYPE  STUSAB  CHARITER  SEQUENCE  LOGRECNO  \\\n",
       "0  FILEID  FILETYPE  STUSAB  CHARITER  SEQUENCE  LOGRECNO   \n",
       "\n",
       "                                        B07401_001  \\\n",
       "0  Population 1 year and over in the United States   \n",
       "\n",
       "                                                      B07401_002  \\\n",
       "0  Population 1 year and over in the United States% 1 to 4 years   \n",
       "\n",
       "                                                       B07401_003  \\\n",
       "0  Population 1 year and over in the United States% 5 to 17 years   \n",
       "\n",
       "                                                         B07401_004  \\\n",
       "0  Population 1 year and over in the United States% 18 and 19 years   \n",
       "\n",
       "                                                       ...                                                        \\\n",
       "0                                                      ...                                                         \n",
       "\n",
       "                                                                                                                                     B07409_021  \\\n",
       "0  Population 25 years and over in the United States% Moved to different county within same state:% High school graduate (includes equivalency)   \n",
       "\n",
       "                                                                                                                            B07409_022  \\\n",
       "0  Population 25 years and over in the United States% Moved to different county within same state:% Some college or associate's degree   \n",
       "\n",
       "                                                                                                           B07409_023  \\\n",
       "0  Population 25 years and over in the United States% Moved to different county within same state:% Bachelor's degree   \n",
       "\n",
       "                                                                                                                         B07409_024  \\\n",
       "0  Population 25 years and over in the United States% Moved to different county within same state:% Graduate or professional degree   \n",
       "\n",
       "                                                                     B07409_025  \\\n",
       "0  Population 25 years and over in the United States% Moved to different state:   \n",
       "\n",
       "                                                                                                     B07409_026  \\\n",
       "0  Population 25 years and over in the United States% Moved to different state:% Less than high school graduate   \n",
       "\n",
       "                                                                                                                  B07409_027  \\\n",
       "0  Population 25 years and over in the United States% Moved to different state:% High school graduate (includes equivalency)   \n",
       "\n",
       "                                                                                                         B07409_028  \\\n",
       "0  Population 25 years and over in the United States% Moved to different state:% Some college or associate's degree   \n",
       "\n",
       "                                                                                        B07409_029  \\\n",
       "0  Population 25 years and over in the United States% Moved to different state:% Bachelor's degree   \n",
       "\n",
       "                                                                                                      B07409_030  \n",
       "0  Population 25 years and over in the United States% Moved to different state:% Graduate or professional degree  \n",
       "\n",
       "[1 rows x 236 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_acs_5year_template(process_year, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>FILETYPE</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>B07401_001</th>\n",
       "      <th>B07401_002</th>\n",
       "      <th>B07401_003</th>\n",
       "      <th>B07401_004</th>\n",
       "      <th>...</th>\n",
       "      <th>B07409_021</th>\n",
       "      <th>B07409_022</th>\n",
       "      <th>B07409_023</th>\n",
       "      <th>B07409_024</th>\n",
       "      <th>B07409_025</th>\n",
       "      <th>B07409_026</th>\n",
       "      <th>B07409_027</th>\n",
       "      <th>B07409_028</th>\n",
       "      <th>B07409_029</th>\n",
       "      <th>B07409_030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FILEID, FILETYPE, STUSAB, CHARITER, SEQUENCE, LOGRECNO, B07401_001, B07401_002, B07401_003, B07401_004, B07401_005, B07401_006, B07401_007, B07401_008, B07401_009, B07401_010, B07401_011, B07401_012, B07401_013, B07401_014, B07401_015, B07401_016, B07401_017, B07401_018, B07401_019, B07401_020, B07401_021, B07401_022, B07401_023, B07401_024, B07401_025, B07401_026, B07401_027, B07401_028, B07401_029, B07401_030, B07401_031, B07401_032, B07401_033, B07401_034, B07401_035, B07401_036, B07401_037, B07401_038, B07401_039, B07401_040, B07401_041, B07401_042, B07401_043, B07401_044, B07401_045, B07401_046, B07401_047, B07401_048, B07401_049, B07401_050, B07401_051, B07401_052, B07401_053, B07401_054, B07401_055, B07401_056, B07401_057, B07401_058, B07401_059, B07401_060, B07401_061, B07401_062, B07401_063, B07401_064, B07401_065, B07401_066, B07401_067, B07401_068, B07401_069, B07401_070, B07401_071, B07401_072, B07401_073, B07401_074, B07401_075, B07401_076, B07401_077, B07401_078, B07401_079, B07401_080, B07402_001, B07402_002, B07402_003, B07402_004, B07402_005, B07403_001, B07403_002, B07403_003, B07403_004, B07403_005, B07403_006, B07403_007, B07403_008, B07403_009, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 236 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_acs_5year_data(process_year,'pa', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write ACSYYYY 5-year description.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if dataset is already defined.  If not, define it as a map, otherwise, leave it alone\n",
    "try:\n",
    "  dataset\n",
    "except NameError:\n",
    "  dataset = {}\n",
    "\n",
    "column_dir = 'columncache'\n",
    "\n",
    "def write_acs_5year_description(year, force_regenerate=False):\n",
    "    dataset[year] = 'acs{year}_5year_tract2010'.format(**locals())\n",
    "    description_path = column_dir + '/' + dataset[year] + '/description.html'\n",
    "\n",
    "    if os.path.exists(description_path) and not force_regenerate:\n",
    "        print '{description_path} already exists, skipping'.format(**locals())\n",
    "        return\n",
    "\n",
    "    table_rows = []\n",
    "\n",
    "    for seqno in range(1, 1000):\n",
    "        template = read_acs_5year_template(year, seqno)\n",
    "        if template is None:\n",
    "            break\n",
    "        for col in range(6, template.shape[1]):\n",
    "            colname = template.columns.values[col]\n",
    "            description = template.iloc[0,col]\n",
    "            try:\n",
    "                description = description.replace(':', '')\n",
    "                description = re.sub(r'\\s*%\\s*', ' &mdash; ', description)\n",
    "            except:\n",
    "                print \"%d:%d col %d description = '%s', using '%s' instead\" % (year, seqno, col, description,colname)\n",
    "                description = colname\n",
    "            # format can't handle array reference, so put dataset[year] in a flat variable for the format to work\n",
    "            dataset_var = dataset[year]\n",
    "            table_rows.append(u'<tr><td>{dataset_var}.{colname}</td><td>{description}</td></tr>\\n'.format(**locals()))\n",
    "\n",
    "    html = '<table>' + ''.join(table_rows) + '</table>'\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(description_path))\n",
    "    except:\n",
    "        pass\n",
    "    open(description_path, 'w').write(html.encode('utf8'))\n",
    "    print 'Wrote %d column names and descriptions to %s' % (len(table_rows), description_path)\n",
    "    print 'Check it out at http://dotmaptiles.createlab.org/data/acs{year}_5year_tract2010'.format(**locals())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009:57 col 128 description = 'nan', using 'B19080_005' instead\n",
      "2009:57 col 134 description = 'nan', using 'B19081_006' instead\n",
      "2009:57 col 140 description = 'nan', using 'B19082_006' instead\n",
      "2009:96 col 49 description = 'nan', using 'B25005_002' instead\n",
      "2009:105 col 6 description = 'nan', using 'B98001_001' instead\n",
      "2009:105 col 7 description = 'nan', using 'B98001_002' instead\n",
      "2009:105 col 8 description = 'nan', using 'B98002_001' instead\n",
      "2009:105 col 9 description = 'nan', using 'B98002_002' instead\n",
      "Wrote 21207 column names and descriptions to columncache/acs2009_5year_tract2010/description.html\n",
      "Check it out at http://dotmaptiles.createlab.org/data/acs2009_5year_tract2010\n"
     ]
    }
   ],
   "source": [
    "write_acs_5year_description(process_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create ACS2015 block-level population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read 2010 block geoids and 2010 block populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_populations has 308745538 total people\n"
     ]
    }
   ],
   "source": [
    "block_populations = numpy.load('columncache/census2010_block2010/p001001.numpy')\n",
    "print 'block_populations has', sum(block_populations), 'total people'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11078297 blocks\n"
     ]
    }
   ],
   "source": [
    "# block_geoids_2010 = [row[0] for row in query_psql(\"SELECT geoid2010 FROM sf1_2010_block_p001 order by blockidx2010\")]\n",
    "block_geoids_2010 = json.load(open('block_geoids_2010.json'))\n",
    "print 'There are', len(block_geoids_2010), 'blocks'\n",
    "\n",
    "assert(len(block_geoids_2010) + 1 == len(block_populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 2010 population by tract and block indices from tract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73057 tracts\n",
      "tract_populations has 308745538 people\n"
     ]
    }
   ],
   "source": [
    "tract_populations = {}\n",
    "tract_block_indexes = {}\n",
    "\n",
    "for block_index_minus_one, block_geoid in enumerate(block_geoids_2010):\n",
    "    block_index = block_index_minus_one + 1\n",
    "    tract_name = block_geoid[0:11] # SSCCCTTTTTT\n",
    "    if tract_name not in tract_populations:\n",
    "        tract_populations[tract_name] = 0\n",
    "        tract_block_indexes[tract_name] = []\n",
    "    tract_populations[tract_name] += block_populations[block_index]\n",
    "    tract_block_indexes[tract_name].append(block_index)\n",
    "\n",
    "print 'There are', len(tract_populations), 'tracts'\n",
    "print 'tract_populations has', sum(tract_populations.values()), 'people'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map tract identifiers to LOGRECNO using geography file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tract_to_logrecno_year=None\n",
    "tract_to_logrecno = {}\n",
    "\n",
    "def compute_tract_to_logrecno(state, year):\n",
    "    global tract_to_logrecno_year\n",
    "    tract_to_logrecno_year=year\n",
    "    \n",
    "    # In the case of 2009, use the 2010 geography files\n",
    "    geo_file_year = year\n",
    "    if(geo_file_year == 2009):\n",
    "        geo_file_year = 2010\n",
    "        \n",
    "    for template in [\"capture/ACS{geo_file_year}_5year/{geo_file_year}_ACS_Geography_Files/g{geo_file_year}5{state}.csv\",\n",
    "                     \"capture/ACS{geo_file_year}_5year/{geo_file_year}_ACS_Geography_Files/geo/g{geo_file_year}5{state}.csv\",\n",
    "                     \"capture/ACS{geo_file_year}_5year/{geo_file_year}_ACS_Geography_Files/tab4/sumfile/prod/2009thru2013/geo/g{geo_file_year}5{state}.csv\",\n",
    "                     \"capture/ACS{geo_file_year}_5year/{geo_file_year}_ACS_Geography_Files/geog/g{geo_file_year}5{state}.csv\"]:\n",
    "        csv_path = template.format(**locals())\n",
    "        if os.path.exists(csv_path):\n",
    "            geography = pandas.read_csv(csv_path,\n",
    "                                        dtype=numpy.str,\n",
    "                                        index_col=False,\n",
    "                                        header=None,\n",
    "                                        keep_default_na=False,\n",
    "                                        na_values=[])\n",
    "\n",
    "            nrows = geography.shape[0]\n",
    "            print 'State {state} has {nrows} geography rows'.format(**locals())\n",
    "    \n",
    "            ntracts = 0\n",
    "            tract_to_logrecno[state] = {}\n",
    "    \n",
    "            for r in range(0, geography.shape[0]):\n",
    "                aggregation_level = geography.iloc[r, 2]\n",
    "                if aggregation_level == '140': # census tract\n",
    "                    tract_identifier = geography.iloc[r, 48][7:]\n",
    "                    logrecno = geography.iloc[r, 4]\n",
    "                    tract_to_logrecno[state][tract_identifier] = logrecno\n",
    "    \n",
    "            print 'Found %d tracts for state %s in year %d' % (len(tract_to_logrecno[state]), state, year)\n",
    "            return\n",
    "\n",
    "    print '{csv_path} missing, call download_geography_data({geo_file_year}), skipping {state},{geo_file_year}'.format(**locals())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State ak has 4193 geography rows\n",
      "Found 167 tracts for state ak in year 2009\n",
      "State al has 11466 geography rows\n",
      "Found 1181 tracts for state al in year 2009\n",
      "State ar has 12182 geography rows\n",
      "Found 686 tracts for state ar in year 2009\n",
      "State az has 11173 geography rows\n",
      "Found 1526 tracts for state az in year 2009\n",
      "State ca has 52857 geography rows\n",
      "Found 8057 tracts for state ca in year 2009\n",
      "State co has 10108 geography rows\n",
      "Found 1249 tracts for state co in year 2009\n",
      "State ct has 6401 geography rows\n",
      "Found 833 tracts for state ct in year 2009\n",
      "State dc has 857 geography rows\n",
      "Found 179 tracts for state dc in year 2009\n",
      "State de has 1714 geography rows\n",
      "Found 218 tracts for state de in year 2009\n",
      "State fl has 28273 geography rows\n",
      "Found 4245 tracts for state fl in year 2009\n",
      "State ga has 16360 geography rows\n",
      "Found 1969 tracts for state ga in year 2009\n",
      "State hi has 3120 geography rows\n",
      "Found 351 tracts for state hi in year 2009\n",
      "State ia has 16074 geography rows\n",
      "Found 825 tracts for state ia in year 2009\n",
      "State id has 3694 geography rows\n",
      "Found 298 tracts for state id in year 2009\n",
      "State il has 33251 geography rows\n",
      "Found 3123 tracts for state il in year 2009\n",
      "State in has 16555 geography rows\n",
      "Found 1511 tracts for state in in year 2009\n",
      "State ks has 12884 geography rows\n",
      "Found 770 tracts for state ks in year 2009\n",
      "State ky has 10596 geography rows\n",
      "Found 1115 tracts for state ky in year 2009\n",
      "State la has 12587 geography rows\n",
      "Found 1148 tracts for state la in year 2009\n",
      "State ma has 11869 geography rows\n",
      "Found 1478 tracts for state ma in year 2009\n",
      "State md has 11272 geography rows\n",
      "Found 1406 tracts for state md in year 2009\n",
      "State me has 4999 geography rows\n",
      "Found 358 tracts for state me in year 2009\n",
      "State mi has 23401 geography rows\n",
      "Found 2813 tracts for state mi in year 2009\n",
      "State mn has 19659 geography rows\n",
      "Found 1338 tracts for state mn in year 2009\n",
      "State mo has 19801 geography rows\n",
      "Found 1393 tracts for state mo in year 2009\n",
      "State ms has 9187 geography rows\n",
      "Found 664 tracts for state ms in year 2009\n",
      "State mt has 4714 geography rows\n",
      "Found 271 tracts for state mt in year 2009\n",
      "State nc has 21777 geography rows\n",
      "Found 2195 tracts for state nc in year 2009\n",
      "State nd has 8092 geography rows\n",
      "Found 205 tracts for state nd in year 2009\n",
      "State ne has 9796 geography rows\n",
      "Found 532 tracts for state ne in year 2009\n",
      "State nh has 3568 geography rows\n",
      "Found 295 tracts for state nh in year 2009\n",
      "State nj has 14388 geography rows\n",
      "Found 2010 tracts for state nj in year 2009\n",
      "State nm has 5991 geography rows\n",
      "Found 499 tracts for state nm in year 2009\n",
      "State nv has 4695 geography rows\n",
      "Found 687 tracts for state nv in year 2009\n",
      "State ny has 34946 geography rows\n",
      "Found 4919 tracts for state ny in year 2009\n",
      "State oh has 28188 geography rows\n",
      "Found 2952 tracts for state oh in year 2009\n",
      "State ok has 11933 geography rows\n",
      "Found 1046 tracts for state ok in year 2009\n",
      "State or has 7807 geography rows\n",
      "Found 834 tracts for state or in year 2009\n",
      "State pa has 29951 geography rows\n",
      "Found 3218 tracts for state pa in year 2009\n",
      "State ri has 1972 geography rows\n",
      "Found 244 tracts for state ri in year 2009\n",
      "State sc has 9356 geography rows\n",
      "Found 1103 tracts for state sc in year 2009\n",
      "State sd has 7045 geography rows\n",
      "Found 222 tracts for state sd in year 2009\n",
      "State tn has 15296 geography rows\n",
      "Found 1497 tracts for state tn in year 2009\n",
      "State tx has 42248 geography rows\n",
      "Found 5265 tracts for state tx in year 2009\n",
      "State ut has 5563 geography rows\n",
      "Found 588 tracts for state ut in year 2009\n",
      "State va has 15731 geography rows\n",
      "Found 1907 tracts for state va in year 2009\n",
      "State vt has 2856 geography rows\n",
      "Found 184 tracts for state vt in year 2009\n",
      "State wa has 12985 geography rows\n",
      "Found 1458 tracts for state wa in year 2009\n",
      "State wi has 18050 geography rows\n",
      "Found 1409 tracts for state wi in year 2009\n",
      "State wv has 6351 geography rows\n",
      "Found 484 tracts for state wv in year 2009\n",
      "State wy has 2214 geography rows\n",
      "Found 132 tracts for state wy in year 2009\n"
     ]
    }
   ],
   "source": [
    "for state in state_names:\n",
    "    compute_tract_to_logrecno(state, process_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate and write columns for data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AW 2/15/18: Randy believes this version is older than the one below.  I discovered this after putting in some work to generalize it to a \n",
    "# parameterized year.  The current version doesn't work.\n",
    "# TODO: can we do this with a data frame then write out columns?\n",
    "\n",
    "# def interpolate_acs_file(year, state, seq):\n",
    "#     print 'Reading %s:%d for %d' % (state, seq, year)\n",
    "#     data = read_acs_5year_data(year, state, seq)\n",
    "\n",
    "#     print 'Mapping locrecno to row'\n",
    "#     logrecnos = data['LOGRECNO']\n",
    "\n",
    "#     logrecno_to_row = {}\n",
    "\n",
    "#     for r, logrecno in enumerate(logrecnos):\n",
    "#         logrecno_to_row[logrecno] = r\n",
    "    \n",
    "#     col_names = data.columns.values[6:]\n",
    "#     print 'Iterating across %d columns' % len(col_names)\n",
    "#     for col_name in col_names:\n",
    "#         input_col = data[col_name]\n",
    "#         output_col_path = column_dir + '/' + dataset + '/' + col_name + '.float32'\n",
    "#         if os.path.exists(output_col_path):\n",
    "#             print '%s already exists, skipping' % output_col_path\n",
    "#             continue\n",
    "\n",
    "#         output_col = numpy.zeros(block_populations.size, dtype=numpy.float32)\n",
    "\n",
    "#         for tract in sorted(tract_to_logrecno[state].keys()):\n",
    "#             input_pop = input_col[logrecno_to_row[tract_to_logrecno[state][tract]]]\n",
    "#             if not isinstance(input_pop, numbers.Number):\n",
    "#                 if input_pop == '.':\n",
    "#                     input_pop = 0\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         input_pop = float(input_pop)\n",
    "#                     except:\n",
    "#                         print 'That population is'\n",
    "#                         print input_pop\n",
    "#                         print type(input_pop)\n",
    "#                         print '>%s<' % input_pop\n",
    "#                         input_pop = 0\n",
    "#             if not tract in tract_block_indexes:\n",
    "#                 print 'missing tract {tract} from tract_block_indexes'.format(**locals())\n",
    "#             else:\n",
    "#                 for block_index in tract_block_indexes[tract]:\n",
    "#                     if block_populations[block_index]:\n",
    "#                         output_col[block_index] = input_pop * float(block_populations[block_index]) / tract_populations[tract]\n",
    "            \n",
    "#         output_col.tofile(output_col_path + '.tmp')\n",
    "#         os.rename(output_col_path + '.tmp', output_col_path)\n",
    "#         print 'Created %s' % output_col_path\n",
    "\n",
    "# for seq in range(97, 2000):\n",
    "#     interpolate_acs_file(year, 'pa', seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: can we do this with a data frame then write out columns?\n",
    "\n",
    "def interpolate_acs_file(year, seq):\n",
    "    global tract_to_logrecno_year\n",
    "    sys.stdout.write(\"interpolating %d:%d\\n\" % (year, seq))\n",
    "    \n",
    "   # Make sure dataset[year] already exists.  If not, prompt to run write_acs_5year_description(year)\n",
    "    try:\n",
    "        dataset[year]\n",
    "    except:\n",
    "        print \"dataset[%d] not defined.  Call write_acs_5year_description(%d) first.\" % (year, year)\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Make sure tract_to_logrecno_year already exists and matches year.  If not, prompt to run compute_tract_to_logrecno(state, %d)\n",
    "    try:\n",
    "        tract_to_logrecno_year\n",
    "    except:\n",
    "        print \"tract_to_logrecno_year not defined.  Call compute_tract_to_logrecno(state, %d) first.\" % (year)\n",
    "        return None\n",
    "\n",
    "    if tract_to_logrecno_year != year:\n",
    "        print \"tract_to_logrecno_year doesn't match.  Call compute_tract_to_logrecno(state, %d) first.\" % (year)\n",
    "        return None\n",
    "    \n",
    "    output_cols = {}\n",
    "    missing_tracts = {}\n",
    "    num_nans=0\n",
    "    for state in state_names:\n",
    "        data = read_acs_5year_data(year, state, seq)\n",
    "    \n",
    "        logrecnos = data['LOGRECNO']\n",
    "\n",
    "        logrecno_to_row = {}\n",
    "\n",
    "        col_names = data.columns.values[6:]\n",
    "        sys.stdout.write('%s:%d %d has %d columns\\n' % (state, seq, year, len(col_names)))\n",
    "        assert len(col_names) < 500   # sanity check to avoid demanding too much RAM on hal15\n",
    "\n",
    "        if state == state_names[0]:\n",
    "            missing = 0\n",
    "            # First state.  Now that we know the col names, let's see if the output files all already exist\n",
    "            for col_name in col_names:\n",
    "                output_col_path = column_dir + '/' + dataset[year] + '/' + col_name + '.float32'\n",
    "                if not os.path.exists(output_col_path):\n",
    "                    missing += 1\n",
    "            if missing == 0:\n",
    "                sys.stdout.write(\"All %d columns for sequence %d already exist, skipping\\n\" % (len(col_names), seq))\n",
    "                return\n",
    "        \n",
    "        for r, logrecno in enumerate(logrecnos):\n",
    "            logrecno_to_row[logrecno] = r\n",
    "    \n",
    "        for col_name in col_names:\n",
    "            input_col = data[col_name]\n",
    "                \n",
    "            if not col_name in output_cols:\n",
    "                output_cols[col_name] = numpy.zeros(block_populations.size, dtype=numpy.float32)\n",
    "            output_col = output_cols[col_name]\n",
    "\n",
    "            for tract in sorted(tract_to_logrecno[state].keys()):\n",
    "                input_pop = input_col[logrecno_to_row[tract_to_logrecno[state][tract]]]\n",
    "                if not isinstance(input_pop, numbers.Number):\n",
    "                    if input_pop == '.':\n",
    "                        input_pop = 0\n",
    "                    else:\n",
    "                        try:\n",
    "                            input_pop = float(input_pop)\n",
    "                        except:\n",
    "                            print 'That population is'\n",
    "                            print input_pop\n",
    "                            print type(input_pop)\n",
    "                            print '>%s<' % input_pop\n",
    "                            input_pop = 0\n",
    "                            \n",
    "                if math.isnan(input_pop):\n",
    "                    #sys.stdout.write('Warning, %s:%d Tract %s is nan\\n' % (state, seq, tract))\n",
    "                    num_nans=num_nans+1\n",
    "\n",
    "                if not tract in tract_block_indexes:\n",
    "                    missing_tracts[tract] = True\n",
    "                else:\n",
    "                    for block_index in tract_block_indexes[tract]:\n",
    "                        if block_populations[block_index]:\n",
    "                            output_col[block_index] = input_pop * float(block_populations[block_index]) / tract_populations[tract]\n",
    "            \n",
    "    sys.stdout.write('Seq %d missing tracts: %s\\n' % (seq, sorted(missing_tracts.keys())))\n",
    "        \n",
    "    if num_nans>0:\n",
    "        sys.stdout.write('Seq %d contains %d nans' % (seq,num_nans))\n",
    "        \n",
    "    for col_name in sorted(output_cols.keys()):\n",
    "        output_col_path = column_dir + '/' + dataset[year] + '/' + col_name + '.float32'\n",
    "        output_cols[col_name].tofile(output_col_path + '.tmp')\n",
    "        os.rename(output_col_path + '.tmp', output_col_path)\n",
    "        sys.stdout.write('Created %s with sum %f\\n' % (output_col_path, output_cols[col_name].sum()))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_acs_5year_data(2009, 'ak', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'B07401_001', u'B07401_002', u'B07401_003', u'B07401_004',\n",
       "       u'B07401_005', u'B07401_006', u'B07401_007', u'B07401_008',\n",
       "       u'B07401_009', u'B07401_010', u'B07401_011', u'B07401_012',\n",
       "       u'B07401_013', u'B07401_014', u'B07401_015', u'B07401_016',\n",
       "       u'B07401_017', u'B07401_018', u'B07401_019', u'B07401_020',\n",
       "       u'B07401_021', u'B07401_022', u'B07401_023', u'B07401_024',\n",
       "       u'B07401_025', u'B07401_026', u'B07401_027', u'B07401_028',\n",
       "       u'B07401_029', u'B07401_030', u'B07401_031', u'B07401_032',\n",
       "       u'B07401_033', u'B07401_034', u'B07401_035', u'B07401_036',\n",
       "       u'B07401_037', u'B07401_038', u'B07401_039', u'B07401_040',\n",
       "       u'B07401_041', u'B07401_042', u'B07401_043', u'B07401_044',\n",
       "       u'B07401_045', u'B07401_046', u'B07401_047', u'B07401_048',\n",
       "       u'B07401_049', u'B07401_050', u'B07401_051', u'B07401_052',\n",
       "       u'B07401_053', u'B07401_054', u'B07401_055', u'B07401_056',\n",
       "       u'B07401_057', u'B07401_058', u'B07401_059', u'B07401_060',\n",
       "       u'B07401_061', u'B07401_062', u'B07401_063', u'B07401_064',\n",
       "       u'B07401_065', u'B07401_066', u'B07401_067', u'B07401_068',\n",
       "       u'B07401_069', u'B07401_070', u'B07401_071', u'B07401_072',\n",
       "       u'B07401_073', u'B07401_074', u'B07401_075', u'B07401_076',\n",
       "       u'B07401_077', u'B07401_078', u'B07401_079', u'B07401_080',\n",
       "       u'B07402_001', u'B07402_002', u'B07402_003', u'B07402_004',\n",
       "       u'B07402_005', u'B07403_001', u'B07403_002', u'B07403_003',\n",
       "       u'B07403_004', u'B07403_005', u'B07403_006', u'B07403_007',\n",
       "       u'B07403_008', u'B07403_009', u'B07403_010', u'B07403_011',\n",
       "       u'B07403_012', u'B07403_013', u'B07403_014', u'B07403_015',\n",
       "       u'B07404A_001', u'B07404A_002', u'B07404A_003', u'B07404A_004',\n",
       "       u'B07404A_005', u'B07404B_001', u'B07404B_002', u'B07404B_003',\n",
       "       u'B07404B_004', u'B07404B_005', u'B07404C_001', u'B07404C_002',\n",
       "       u'B07404C_003', u'B07404C_004', u'B07404C_005', u'B07404D_001',\n",
       "       u'B07404D_002', u'B07404D_003', u'B07404D_004', u'B07404D_005',\n",
       "       u'B07404E_001', u'B07404E_002', u'B07404E_003', u'B07404E_004',\n",
       "       u'B07404E_005', u'B07404F_001', u'B07404F_002', u'B07404F_003',\n",
       "       u'B07404F_004', u'B07404F_005', u'B07404G_001', u'B07404G_002',\n",
       "       u'B07404G_003', u'B07404G_004', u'B07404G_005', u'B07404H_001',\n",
       "       u'B07404H_002', u'B07404H_003', u'B07404H_004', u'B07404H_005',\n",
       "       u'B07404I_001', u'B07404I_002', u'B07404I_003', u'B07404I_004',\n",
       "       u'B07404I_005', u'B07407_001', u'B07407_002', u'B07407_003',\n",
       "       u'B07407_004', u'B07407_005', u'B07407_006', u'B07407_007',\n",
       "       u'B07407_008', u'B07407_009', u'B07407_010', u'B07407_011',\n",
       "       u'B07407_012', u'B07407_013', u'B07407_014', u'B07407_015',\n",
       "       u'B07407_016', u'B07407_017', u'B07407_018', u'B07407_019',\n",
       "       u'B07407_020', u'B07407_021', u'B07407_022', u'B07407_023',\n",
       "       u'B07407_024', u'B07407_025', u'B07408_001', u'B07408_002',\n",
       "       u'B07408_003', u'B07408_004', u'B07408_005', u'B07408_006',\n",
       "       u'B07408_007', u'B07408_008', u'B07408_009', u'B07408_010',\n",
       "       u'B07408_011', u'B07408_012', u'B07408_013', u'B07408_014',\n",
       "       u'B07408_015', u'B07408_016', u'B07408_017', u'B07408_018',\n",
       "       u'B07408_019', u'B07408_020', u'B07408_021', u'B07408_022',\n",
       "       u'B07408_023', u'B07408_024', u'B07408_025', u'B07408_026',\n",
       "       u'B07408_027', u'B07408_028', u'B07408_029', u'B07408_030',\n",
       "       u'B07409_001', u'B07409_002', u'B07409_003', u'B07409_004',\n",
       "       u'B07409_005', u'B07409_006', u'B07409_007', u'B07409_008',\n",
       "       u'B07409_009', u'B07409_010', u'B07409_011', u'B07409_012',\n",
       "       u'B07409_013', u'B07409_014', u'B07409_015', u'B07409_016',\n",
       "       u'B07409_017', u'B07409_018', u'B07409_019', u'B07409_020',\n",
       "       u'B07409_021', u'B07409_022', u'B07409_023', u'B07409_024',\n",
       "       u'B07409_025', u'B07409_026', u'B07409_027', u'B07409_028',\n",
       "       u'B07409_029', u'B07409_030'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrecnos = data['LOGRECNO']\n",
    "col_names = data.columns.values[6:]\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: LOGRECNO, dtype: object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrecnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logrecno_to_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-40ddcb169e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtract\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtract_to_logrecno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtract_to_logrecno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtract\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogrecno_to_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtract_to_logrecno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtract\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logrecno_to_row' is not defined"
     ]
    }
   ],
   "source": [
    "for tract in sorted(tract_to_logrecno['ak'].keys()):\n",
    "    print \"%s %s\" % (tract_to_logrecno['ak'][tract], logrecno_to_row[tract_to_logrecno['ak'][tract]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating 2009:1\n",
      "ak:1 2009 has 230 columns\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0001037'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2a1197a641c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpolate_acs_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-1be0d8d8351e>\u001b[0m in \u001b[0;36minterpolate_acs_file\u001b[0;34m(year, seq)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtract\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtract_to_logrecno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0minput_pop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogrecno_to_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtract_to_logrecno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtract\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0minput_pop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0001037'"
     ]
    }
   ],
   "source": [
    "interpolate_acs_file(process_year, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating 2010:1\n",
      "interpolating 2010:3\n",
      "interpolating 2010:2\n",
      "interpolating 2010:4\n",
      "ak:1 2010 has 230 columns\n",
      "All 230 columns for sequence 1 already exist, skipping\n",
      "ak:3 2010 has 237 columns\n",
      "interpolating 2010:5\n",
      "ak:5 2010 has 175 columns\n",
      "ak:2 2010 has 95 columns\n",
      "ak:4 2010 has 217 columns\n",
      "al:2 2010 has 95 columns\n",
      "al:5 2010 has 175 columns\n",
      "al:4 2010 has 217 columns\n",
      "al:3 2010 has 237 columns\n",
      "ar:2 2010 has 95 columns\n",
      "az:2 2010 has 95 columns\n"
     ]
    }
   ],
   "source": [
    "# 4 seems conservative on a 64GB machine\n",
    "pool = SimpleProcessPoolExecutor(4)\n",
    "\n",
    "for seq in range(1, 1000):\n",
    "    pool.submit(interpolate_acs_file, process_year, seq)\n",
    "\n",
    "pool.shutdown()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for capture/ACS2015_5year/group2/e20155ak0001000.txt\n"
     ]
    }
   ],
   "source": [
    "data = read_acs_5year_data(2015, 'ak', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logrecnos = data['LOGRECNO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000617'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tract_to_logrecno['ak']['02198000300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(logrecnos)):\n",
    "    if(logrecnos[i]=='0000617'):\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'B00001_001', u'B00002_001'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = data.columns.values[6:]\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tract_block_indexes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -l columncache/acs2015_5year_tract2010/B08006_002.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=numpy.memmap('columncache/acs2015_5year_tract2010/B00001_001.float32', dtype=numpy.float32, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap(nan, dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 0.        ,  7.81642246,  0.        , ...,  1.24807394,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
