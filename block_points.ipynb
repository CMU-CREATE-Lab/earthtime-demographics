{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is based off of http://localhost:8820/notebooks/projects/demographics/Voting-2018-AW8.ipynb\n",
    "# and is intended to give access to block_points functionality from other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random points in census blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://localhost:8820/notebooks/projects/demographics/Get%20random%20census%20block%20points%20from%20prototiles.ipynb\n",
    "# These are filled in by calling init_block_points\n",
    "try:\n",
    "    all_pts\n",
    "    block_geoids_2010\n",
    "    blk_geoid2idx\n",
    "except:\n",
    "    all_pts = None\n",
    "    block_geoids_2010 = None\n",
    "    blk_geoid2idx = {}\n",
    "\n",
    "# This needs to be called once before using block_points functionality\n",
    "def init_block_points():\n",
    "    global block_geoids_2010\n",
    "    global blk_geoid2idx\n",
    "    global all_pts\n",
    "\n",
    "    if not all_pts:\n",
    "        print \"Loading prototiles\"\n",
    "        numpy_record_type = [('x','<f4'), ('y','<f4'), ('blockIdx', '<i4'), ('subIdx', '<i4')]\n",
    "        all_pts = np.memmap('prototiles/master-sorted-by-block.bin', dtype=numpy_record_type)\n",
    "\n",
    "    if not block_geoids_2010:\n",
    "        print \"Loading block_geoids_2010\"\n",
    "        block_geoids_2010 = json.load(open('block_geoids_2010.json'))\n",
    "\n",
    "    if len(blk_geoid2idx)==0:\n",
    "        print \"Initializing blk_geoid2idx\"\n",
    "        for i in range(0, len(block_geoids_2010)):\n",
    "            blk_geoid2idx[block_geoids_2010[i]] = i+1\n",
    "\n",
    "    print \"Done initializing block_points\"\n",
    "    \n",
    "def find_point_idx(block_idx):\n",
    "    global all_pts\n",
    "    \n",
    "    try:\n",
    "        all_pts\n",
    "    except:\n",
    "        init_block_points()\n",
    "\n",
    "    min_idx = 0\n",
    "    max_idx = len(all_pts) - 1\n",
    "    while min_idx <= max_idx:\n",
    "        test_idx = int((min_idx + max_idx) / 2)\n",
    "        if block_idx > all_pts[test_idx][2]:\n",
    "            min_idx = test_idx + 1\n",
    "        elif block_idx < all_pts[test_idx][2] or all_pts[test_idx][3] != 0:\n",
    "            max_idx = test_idx - 1\n",
    "        else:\n",
    "            return test_idx\n",
    "    return [min_idx, max_idx]\n",
    "\n",
    "        \n",
    "def block_points(block_idx):\n",
    "    global all_pts\n",
    "\n",
    "    try:\n",
    "        all_pts\n",
    "    except:\n",
    "        init_block_points()\n",
    "        \n",
    "    ret = []\n",
    "    idx = find_point_idx(block_idx)\n",
    "    assert all_pts[idx][2] == block_idx and all_pts[idx][3] == 0\n",
    "    while idx < len(all_pts):\n",
    "        if all_pts[idx][2] == block_idx:\n",
    "            ret.append({'x':all_pts[idx][0], 'y':all_pts[idx][1]})\n",
    "        else:\n",
    "            break\n",
    "        idx += 1\n",
    "    return ret\n",
    "\n",
    "# For each census block, keep track of what voter each index has been assigned to\n",
    "# Top level key is census block number, secondary key is 'next' for keeping track of the next index to be assigned,\n",
    "# 'points' for the value returned by block_points, and voter ID: index for other entries\n",
    "try:\n",
    "    block_id_use_map\n",
    "except:\n",
    "    block_id_use_map={}\n",
    "\n",
    "# Save/load for block_id_use_map \n",
    "#   block_id_use_map_05_09_13_17_18_18_18_a.pickle has the dot mapping used for the _h series of dots.\n",
    "block_id_use_map_file_path_t = 'voters/block_id_use_map_{}.pickle'\n",
    "default_bium_suffix = '05_09_13_17_18_18_18_a'\n",
    "\n",
    "def save_block_id_use_map(suffix):\n",
    "    global block_id_use_map\n",
    "    global block_id_use_map_file_path_t\n",
    "    \n",
    "    if not suffix:\n",
    "        print \"ERROR: need to specify suffix to save block_id_use_map.  Default load suffix is %s\"%(default_bium_suffix)\n",
    "        \n",
    "    block_id_use_map_file_path = block_id_use_map_file_path_t.format(suffix)\n",
    "    \n",
    "    print 'Saving block_id_use_map to %s'%(block_id_use_map_file_path)\n",
    "\n",
    "    # Save out block_id_use_map\n",
    "    with open(block_id_use_map_file_path, 'wb') as handle:\n",
    "        pickle.dump(block_id_use_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_block_id_use_map(suffix):\n",
    "    global block_id_use_map\n",
    "    global block_id_use_map_file_path_t\n",
    "    global default_bium_suffix\n",
    "\n",
    "    if not suffix:\n",
    "        suffix = default_bium_suffix\n",
    "    block_id_use_map_file_path = block_id_use_map_file_path_t.format(suffix)\n",
    "    \n",
    "    print 'Loading block_id_use_map from %s'%(block_id_use_map_file_path)\n",
    "\n",
    "    # Load in prep_fad_map\n",
    "    with open(block_id_use_map_file_path, 'rb') as handle:\n",
    "        block_id_use_map = pickle.load(handle)\n",
    "\n",
    "# Hold onto the value returned by block_points.  \n",
    "# key is census block number.  Value is an array returned by block_points.\n",
    "# This doesn't need to be saved out because it can be regenerated at will from \n",
    "# block_points\n",
    "try:\n",
    "    block_points_map\n",
    "except:\n",
    "    block_points_map={}\n",
    "\n",
    "# Keep track of which census blocks overflowed the number of points\n",
    "try:\n",
    "    block_id_overflow_set\n",
    "except:\n",
    "    block_id_overflow_set=set()\n",
    "\n",
    "def LonLatToWebMercator(lon, lat):\n",
    "    x = (lon + 180.0) * 256.0 / 360.0\n",
    "    y = 128.0 - math.log(math.tan((lat + 90.0) * math.pi / 360.0)) * 128.0 / math.pi\n",
    "    return [x, y]\n",
    "\n",
    "def WebMercatorToLonLat(x,y):\n",
    "    lat = math.atan(math.exp((128.0 - y) * math.pi / 128.0)) * 360.0 / math.pi - 90.0\n",
    "    lon = x * 360.0 / 256.0 - 180.0\n",
    "    return [lon, lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_get_coords(census_block, item_id):\n",
    "    global block_id_use_map\n",
    "    global blk_geoid2idx\n",
    "    global block_points_map\n",
    "    \n",
    "    if(not census_block in block_id_use_map):\n",
    "        # Need to create an entry, set 'next' to 0, initialize points\n",
    "        # First convert from GEOID10 to the index into the block_idx\n",
    "        block_idx = blk_geoid2idx[census_block]\n",
    "        point_arr = block_points(block_idx)\n",
    "        block_id_use_map[census_block]={'next':0, 'numpoints':len(point_arr)}\n",
    "        block_points_map[census_block]=point_arr\n",
    "    elif(not census_block in block_points_map):\n",
    "        # We have an entry in block_id_use_map for this census_block, \n",
    "        # but not in block_points_map.  This can happen if we restore\n",
    "        # block_id_use_map from a saved file.  Use block_points to fill in \n",
    "        # block_points_map\n",
    "        block_idx = blk_geoid2idx[census_block]\n",
    "        point_arr = block_points(block_idx)\n",
    "        block_points_map[census_block]=point_arr\n",
    "        \n",
    "    # We know census_block is in block_id_use_map (which we may have just added)\n",
    "    # Check if this ID is already registered\n",
    "    if(item_id in block_id_use_map[census_block]):\n",
    "        # Already assigned, just use the same index as before\n",
    "        point_idx=block_id_use_map[census_block][item_id]\n",
    "    else:\n",
    "        # Not yet assigned, take the next available \n",
    "        # and increment 'next'\n",
    "        point_idx = block_id_use_map[census_block]['next']\n",
    "        if(point_idx>block_id_use_map[census_block]['numpoints']-1):\n",
    "            # Overflow\n",
    "            if(not census_block in block_id_overflow_set):\n",
    "                block_id_overflow_set.add(census_block)\n",
    "                print \"WARNING: overflow in census block %s\" % (census_block)\n",
    "            # For now, just start reassigning numbers back at 0\n",
    "            point_idx=0\n",
    "            block_id_use_map[census_block]['next']=0\n",
    "        block_id_use_map[census_block]['next'] = point_idx + 1\n",
    "        block_id_use_map[census_block][item_id] = point_idx\n",
    "        \n",
    "    # Retrieve the webmercator point from the points array.\n",
    "    # Convert it to lat lon and create a Point to return.\n",
    "    # Note that WebMercatorToLonLat(x,y) returns [lon, lat]\n",
    "    # the args to create a Point are also (lon, lat)\n",
    "    point_xy = block_points_map[census_block][point_idx]\n",
    "    ll_arr = WebMercatorToLonLat(point_xy['x'],point_xy['y'])\n",
    "    return Point(ll_arr[0], ll_arr[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block_get_coords('420034886004011', '33-0941669_X_82_41.0_1.93_42003488600_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://localhost:8820/notebooks/projects/demographics/Import%20Opportunity%20Atlas.ipynb\n",
    "# Do tract->block mappings\n",
    "try:\n",
    "    tract_block_indexes\n",
    "except:\n",
    "    tract_block_indexes = {}\n",
    "    \n",
    "def init_tract_block_indexes():\n",
    "    global tract_block_indexes\n",
    "    global block_geoids_2010\n",
    "    \n",
    "    if not block_geoids_2010 or len(block_geoids_2010)==0:\n",
    "        init_block_points()\n",
    "       \n",
    "    if len(tract_block_indexes)==0:\n",
    "        for block_index_minus_one, block_geoid in enumerate(block_geoids_2010):\n",
    "            block_index = block_index_minus_one + 1\n",
    "            tract_name = block_geoid[0:11] # SSCCCTTTTTT\n",
    "            if tract_name in tract_block_indexes:\n",
    "                tract_block_indexes[tract_name].append(block_index)\n",
    "            else:\n",
    "                tract_block_indexes[tract_name]=[block_index]\n",
    "\n",
    "    print 'There are', len(tract_block_indexes), 'tracts in tract_block_indexes'\n",
    "    \n",
    "def get_tract_block_indexes(tract_id):\n",
    "    global tract_block_indexes\n",
    "\n",
    "    if not tract_block_indexes or len(tract_block_indexes)==0:\n",
    "        init_tract_block_indexes()\n",
    "        \n",
    "    if tract_id in tract_block_indexes:\n",
    "        return tract_block_indexes[tract_id]\n",
    "    return []\n",
    "\n",
    "def get_tract_block_geoids(tract_id):\n",
    "    global tract_block_indexes\n",
    "\n",
    "    if not tract_block_indexes or len(tract_block_indexes)==0:\n",
    "        init_tract_block_indexes()\n",
    "        \n",
    "    if tract_id in tract_block_indexes:\n",
    "        return map(lambda x: block_geoids_2010[x-1],tract_block_indexes[tract_id])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tract_block_indexes['42003160300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter(lambda x: x[0:8] == '42003160',block_geoids_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_tract_block_geoids('42003202300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths to initialize tract_populations for a given type of population\n",
    "# tract_populations can reflect many different kinds of populations, so don't \n",
    "# make this global.  The notebook using it needs to hold on to it\n",
    "pop_col_paths = {'all':'columncache/census2010_block2010/p001001.numpy',\n",
    "                 'rental_pop':'columncache/census2010_block2010/H0110004.numpy',\n",
    "                 'rentals':'columncache/census2010_block2010/H0040004.numpy',\n",
    "                 'black_renters':'columncache/census2010_block2010/h014012.numpy',\n",
    "                 'white_renters':'columncache/census2010_block2010/h014011.numpy'\n",
    "                }\n",
    "\n",
    "try:\n",
    "    tract_population_map\n",
    "    blk_population_map\n",
    "except:\n",
    "    tract_population_map={}\n",
    "    blk_population_map={}\n",
    "    \n",
    "def get_tract_populations(pop_type):\n",
    "    if not pop_type in pop_col_paths:\n",
    "        print \"Unknown population type in get_tract_populations.  Add %s to pop_col_paths and try again\" %(pop_type)\n",
    "        return None\n",
    "    \n",
    "    # Check if we already have a map for this population\n",
    "    if pop_type in tract_population_map:\n",
    "        return tract_population_map[pop_type]\n",
    "    \n",
    "    if pop_type not in blk_population_map:\n",
    "        blk_population_map[pop_type]={}\n",
    "    \n",
    "    # Don't have this population loaded yet\n",
    "    block_populations = np.load(pop_col_paths[pop_type])\n",
    "    \n",
    "    print 'block_populations for', pop_type, 'has', sum(block_populations), 'total people'\n",
    "    \n",
    "    tract_populations = {}\n",
    "\n",
    "    for block_index_minus_one, block_geoid in enumerate(block_geoids_2010):\n",
    "        block_index = block_index_minus_one + 1\n",
    "        tract_name = block_geoid[0:11] # SSCCCTTTTTT\n",
    "        if block_geoid not in blk_population_map[pop_type]:\n",
    "            blk_population_map[pop_type][block_geoid]=block_populations[block_index]\n",
    "            \n",
    "        if tract_name not in tract_populations:\n",
    "            tract_populations[tract_name] = 0\n",
    "        tract_populations[tract_name] += block_populations[block_index]\n",
    "\n",
    "    print 'tract_populations for', pop_type, 'has', sum(tract_populations.values()), 'people'\n",
    "    \n",
    "    # Hold onto this in case someone asks again later\n",
    "    tract_population_map[pop_type] = tract_populations\n",
    "    \n",
    "    return tract_populations\n",
    "\n",
    "def get_block_populations(pop_type):\n",
    "    if not pop_type in pop_col_paths:\n",
    "        print \"Unknown population type in get_block_populations.  Add %s to pop_col_paths and try again\" %(pop_type)\n",
    "        return None\n",
    "    \n",
    "    # Check if we already have a map for this population\n",
    "    if pop_type in blk_population_map:\n",
    "        return blk_population_map[pop_type]\n",
    "    \n",
    "    # Don't have this population loaded yet\n",
    "    get_tract_populations(pop_type)\n",
    "    return blk_population_map[pop_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_block_populations('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_tract_populations('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#blk_population_map['all']['420035630001013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73057 tracts in tract_block_indexes\n"
     ]
    }
   ],
   "source": [
    "#init_tract_block_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'01001020100' in tract_block_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
